{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projet : Accident de la route\n",
    "==============\n",
    "\n",
    "## Etape 3 : Modélisation\n",
    "\n",
    "### Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import des librairies\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.max_info_columns\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from lazypredict.supervised import LazyClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place</th>\n",
       "      <th>catu</th>\n",
       "      <th>grav</th>\n",
       "      <th>sexe</th>\n",
       "      <th>trajet</th>\n",
       "      <th>secu1</th>\n",
       "      <th>locp</th>\n",
       "      <th>catr</th>\n",
       "      <th>circ</th>\n",
       "      <th>nbv</th>\n",
       "      <th>vosp</th>\n",
       "      <th>prof</th>\n",
       "      <th>plan</th>\n",
       "      <th>surf</th>\n",
       "      <th>infra</th>\n",
       "      <th>situ</th>\n",
       "      <th>vma</th>\n",
       "      <th>lum</th>\n",
       "      <th>com</th>\n",
       "      <th>agg</th>\n",
       "      <th>int</th>\n",
       "      <th>atm</th>\n",
       "      <th>col</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>senc</th>\n",
       "      <th>catv</th>\n",
       "      <th>obs</th>\n",
       "      <th>obsm</th>\n",
       "      <th>choc</th>\n",
       "      <th>manv</th>\n",
       "      <th>motor</th>\n",
       "      <th>age_group</th>\n",
       "      <th>h_group</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>26198</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>44.56</td>\n",
       "      <td>4.73</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>26198</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>44.56</td>\n",
       "      <td>4.73</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>25204</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>46.93</td>\n",
       "      <td>6.35</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>25204</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>46.93</td>\n",
       "      <td>6.35</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>22360</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>48.49</td>\n",
       "      <td>-2.76</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   place  catu  grav  sexe  trajet  secu1  locp  catr  circ  nbv  vosp  prof  \\\n",
       "0      1     1     1     1       5      1    -1     4     2    2     0     1   \n",
       "1      1     1     0     1       5      1    -1     4     2    2     0     1   \n",
       "2      1     1     1     1       9      1     0     4     2    2     0     1   \n",
       "3      1     1     0     1       4      1     0     4     2    2     0     1   \n",
       "4      1     1     0     1       0      1    -1     3    -1    2     0     1   \n",
       "\n",
       "   plan  surf  infra  situ  vma  lum    com  agg  int  atm  col   lat  long  \\\n",
       "0     1     1      0     1   50    1  26198    2    3    1    3 44.56  4.73   \n",
       "1     1     1      0     1   50    1  26198    2    3    1    3 44.56  4.73   \n",
       "2     1     1      0     1   50    1  25204    2    3    1    3 46.93  6.35   \n",
       "3     1     1      0     1   50    1  25204    2    3    1    3 46.93  6.35   \n",
       "4     1     1      5     1   50    1  22360    2    6    1    2 48.49 -2.76   \n",
       "\n",
       "   senc  catv  obs  obsm  choc  manv  motor  age_group  h_group  weekday  \n",
       "0     1     3    0     2     1     9      1          2        6        2  \n",
       "1     1     6    0     2     2     1      1          7        6        2  \n",
       "2     2     6    0     2     8    15      1          4        3        3  \n",
       "3     2     5    0     2     1     1      1          6        3        3  \n",
       "4     2     6    0     2     1     2      1          3        6        3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import du dataset\n",
    "df = pd.read_csv(\"dataset/dataset_final.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Séparation des labels et targets : (319499, 34) (136929, 34) (319499,) (136929,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop([\"grav\"], axis=1), df.grav, test_size=0.3)\n",
    "print(\"Séparation des labels et targets :\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choisir la meilleure sélection de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur nombre de variables : 32\n",
      "Meilleur F1 score: 0.7409953911273341\n"
     ]
    }
   ],
   "source": [
    "best_f1_score_lr = 0\n",
    "best_k_lr = 0\n",
    "\n",
    "for k in range(1, X_train_scaled.shape[1] + 1):\n",
    "    select_k_best_lr = SelectKBest(score_func=f_classif, k=k)\n",
    "    \n",
    "    X_train_k_best_lr = select_k_best_lr.fit_transform(X_train_scaled, y_train)\n",
    "    X_test_k_best_lr = select_k_best_lr.transform(X_test_scaled)\n",
    "    \n",
    "    model_k_lr = OneVsRestClassifier(LogisticRegression(random_state=0, solver='lbfgs', max_iter=1000))\n",
    "    model_k_lr.fit(X_train_k_best_lr, y_train)\n",
    "    \n",
    "    y_pred_k_lr = model_k_lr.predict(X_test_k_best_lr)\n",
    "    f1_k_lr = f1_score(y_test, y_pred_k_lr, average='weighted')\n",
    "    \n",
    "    if f1_k_lr > best_f1_score_lr:\n",
    "        best_f1_score_lr = f1_k_lr\n",
    "        best_k_lr = k\n",
    "\n",
    "print(\"Meilleur nombre de variables :\", best_k_lr)\n",
    "print(\"Meilleur F1 score:\", best_f1_score_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application de la meilleure sélection de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319499, 32) (136929, 32)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectKBest(f_classif, k=best_k_lr)\n",
    "\n",
    "X_train_kb = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_kb = selector.transform(X_test_scaled)\n",
    "\n",
    "print(X_train_kb.shape, X_test_kb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 185996, number of negative: 133503\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 319499, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582149 -> initscore=0.331601\n",
      "[LightGBM] [Info] Start training from score 0.331601\n",
      "Matrice de confusion :\n",
      " [[44338 12611]\n",
      " [13742 66238]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "model_test = LGBMClassifier(random_state=42)\n",
    "model_test.fit(X_train_scaled, y_train)\n",
    "y_pred_test = model_test.predict(X_test_scaled)\n",
    "\n",
    "cm_lr_test = confusion_matrix(y_test, y_pred_test)\n",
    "print(\"Matrice de confusion :\\n\", cm_lr_test)\n",
    "\n",
    "row_sums_lr_test = cm_lr_test.sum(axis = 1)\n",
    "cm_percent_lr_test = (cm_lr_test.T / row_sums_lr_test).T * 100\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_percent_lr_test, annot = True, fmt = \".2f\", cmap = \"Blues\")\n",
    "plt.xlabel('Classe prédite')\n",
    "plt.ylabel('Classe réelle')\n",
    "plt.title('Matrice de confusion avec pourcentages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_lgbm = {\n",
    "#    'learning_rate': [0.01, 0.1, 1.0],                # Taux d'apprentissage\n",
    "    'n_estimators': [50, 70,100],                  # Nombre d'estimateurs\n",
    "    'metric': ['aucpr'],\n",
    "    'objective': ['binary'],\n",
    "    'num_leaves': [50, 60, 70, 80],                       # Nombre maximum de feuilles par arbre\n",
    "    'boosting_type': ['gbdt', 'dart']#,        # Type de boosting\n",
    "#    'subsample': [0.8, 1.0],                          # Sous-échantillonnage des données\n",
    "#    'colsample_bytree': [0.8, 1.0]                   # Fraction de colonnes à utiliser par arbre\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_lgbm = GridSearchCV(estimator=LGBMClassifier(n_iter=1000),\n",
    "                           param_grid= hp_lgbm,\n",
    "                           \n",
    "                         #  cv=3,  # Nombre de folds pour la validation croisée\n",
    "                           verbose=True,\n",
    "                           return_train_score=True,\n",
    "                            refit=True,\n",
    "                            scoring='average_precision',\n",
    "                           n_jobs=-1)  # Utiliser tous les coeurs du CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.224119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1055\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.375802 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1053\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.305228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1055\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.130434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1053[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.317044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1052\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.438857 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1052\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.477593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1055\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.169180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "\n",
      "[LightGBM] [Info] Total Bins 1052\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.298497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1052\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.328483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1055\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.378113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1053\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.349873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1053\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's binary_logloss: 0.400905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.835104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1055\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's binary_logloss: 0.401299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.848104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1053\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's binary_logloss: 0.401081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.512335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1052\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's binary_logloss: 0.401077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.866822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1055\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's binary_logloss: 0.400461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.858622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1053\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's binary_logloss: 0.400603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.717100 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1052\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's binary_logloss: 0.400036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.730819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1055\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's binary_logloss: 0.40017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.867587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1053\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's binary_logloss: 0.398958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.788352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1052\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's binary_logloss: 0.399534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.829289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1055\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's binary_logloss: 0.398803\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's binary_logloss: 0.399142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.938938 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1053\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.649872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1052\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's binary_logloss: 0.400905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.848408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1055\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's binary_logloss: 0.401081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.807473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1053\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's binary_logloss: 0.401299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.977137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1052\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's binary_logloss: 0.401077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.001326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1055\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's binary_logloss: 0.400461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.794086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1053\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's binary_logloss: 0.400603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.897990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1052\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's binary_logloss: 0.398958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.840709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1055\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's binary_logloss: 0.400905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.891631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1053\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's binary_logloss: 0.400036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.857954 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1052\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's binary_logloss: 0.401081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.777381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1055\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's binary_logloss: 0.398803\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's binary_logloss: 0.399534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.737173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1053\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.828944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1052\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's binary_logloss: 0.401077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.828658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1055\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/callback.py:329: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's binary_logloss: 0.400461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.829413 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1053\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/callback.py:329: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's binary_logloss: 0.40017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.846930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1052\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/callback.py:329: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's binary_logloss: 0.401299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.748094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1055\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/callback.py:329: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's binary_logloss: 0.399142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.817628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1053\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/callback.py:329: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's binary_logloss: 0.400603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] Number of positive: 86902, number of negative: 62196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.738084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1052\n",
      "[LightGBM] [Info] Number of data points in the train set: 149098, number of used features: 33\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582852 -> initscore=0.334490\n",
      "[LightGBM] [Info] Start training from score 0.334490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/lightgbm/callback.py:329: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning(\"Early stopping is not available in dart mode\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 19\u001b[0m\n\u001b[1;32m      5\u001b[0m fit_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_set\u001b[39m\u001b[38;5;124m\"\u001b[39m: [(X_val, y_val)],\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_metric\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m     10\u001b[0m gs_lgbm \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mLGBMClassifier(n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m), \n\u001b[1;32m     11\u001b[0m                        param_grid\u001b[38;5;241m=\u001b[39mhp_lgbm, \n\u001b[1;32m     12\u001b[0m                        verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m                             n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     17\u001b[0m                        cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mgs_lgbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_sub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_sub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/model_selection/_search.py:968\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    962\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    963\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    964\u001b[0m     )\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 968\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    972\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1543\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1542\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1543\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/model_selection/_search.py:914\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    910\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    911\u001b[0m         )\n\u001b[1;32m    912\u001b[0m     )\n\u001b[0;32m--> 914\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    934\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    935\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m     )\n",
      "File \u001b[0;32m~/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "X_train_sub, X_val, y_train_sub, y_val = train_test_split(X_train_scaled, y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "fit_params = {\n",
    "    \"eval_set\": [(X_val, y_val)],\n",
    "    \"eval_metric\": 'logloss'\n",
    "}\n",
    "\n",
    "gs_lgbm = GridSearchCV(estimator=LGBMClassifier(n_iter=1000), \n",
    "                       param_grid=hp_lgbm, \n",
    "                       verbose=True,\n",
    "                           return_train_score=True,\n",
    "                            refit=True,\n",
    "                            scoring='f1',\n",
    "                            n_jobs=-1,\n",
    "                       cv=3)\n",
    "\n",
    "gs_lgbm.fit(X_train_sub, y_train_sub, **fit_params, \n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=3)]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres trouvés: {'boosting_type': 'dart', 'metric': 'aucpr', 'n_estimators': 50, 'num_leaves': 80, 'objective': 'binary'}\n",
      "Meilleur score de validation croisée: 0.8133369693569837\n"
     ]
    }
   ],
   "source": [
    "best_hp_lgbm = gs_lgbm.best_params_\n",
    "best_score_lgbm = gs_lgbm.best_score_\n",
    "best_estimator_lgbm = gs_lgbm.best_estimator_\n",
    "\n",
    "print(\"Meilleurs paramètres trouvés:\", best_hp_lgbm)\n",
    "print(\"Meilleur score de validation croisée:\", best_score_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgbm = best_estimator_lgbm.predict(X_test_scaled)\n",
    "\n",
    "cv_results_lgbm = gs_lgbm.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrice de confusion de lgbm classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      " [[44823 12263]\n",
      " [12834 67009]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAIkCAYAAACOQJrbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABVaklEQVR4nO3dd1yV9f//8ecBWbJdgHuhqDkSF85UEneO3OXIzEpNJRt+1NAycVSOHJWVtkxzpuUqKytXrsy9R6XgRlEBhev3Rz/PtxOgHOUAcj3u3a7bzfO+3ud9va4D2MvX+329sRiGYQgAAACm4ZTdAQAAACBrkQACAACYDAkgAACAyZAAAgAAmAwJIAAAgMmQAAIAAJgMCSAAAIDJkAACAACYDAkgAACAyZAA4oEyevRoWSyW7A5DkjR37lxZLBadOHEiu0O5b6tXr1a1atXk7u4ui8Wiy5cvZ+r4uemzAoDcgAQQabr9P2yLxaJff/011XnDMFSsWDFZLBa1bt36nq4xbtw4LVu27D4jxf26cOGCOnfuLA8PD82YMUOfffaZPD09szssQJI0c+ZMzZ07N7vDAHIdEkDckbu7u+bNm5eqff369frrr7/k5uZ2z2PfSwI4cuRI3bhx456vidS2bt2qq1ev6o033lDfvn31xBNPyMXFJVOv8eSTT+rGjRsqUaJEpo6L3I8EEHAMEkDcUcuWLbVw4ULdunXLpn3evHkKDQ1VYGBglsRx7do1SVKePHnk7u6eJdc0i7Nnz0qS/Pz8HHYNZ2dn6/QyHiwJCQlKSUnJ7jAAZDISQNxRt27ddOHCBX333XfWtqSkJC1atEjdu3dP8z1vvfWW6tatq/z588vDw0OhoaFatGiRTR+LxaJr167pk08+sU419+7dW9L/rfPbt2+funfvLn9/f9WvX9/m3H99/vnnqlWrlvLmzSt/f381bNhQa9eutemzatUqNWjQQJ6envL29larVq20d+/eDH0Oe/fuVZMmTeTh4aGiRYtq7Nix6f5P8X6uc/nyZQ0dOlQlS5aUm5ubihYtqp49e+r8+fPWPmfPnlXfvn0VEBAgd3d3Va1aVZ988onNOCdOnJDFYtFbb72lDz74QGXKlJGbm5tq1qyprVu3Wvs98sgj6tWrlySpZs2aNl+HkiVLWv/8b4888ogeeeQRm7Z3331XlSpVsn7+NWrUsKkcp7cGcObMmapUqZLc3NxUuHBhDRgwINX6w0ceeUQPPfSQ9u3bp8aNGytv3rwqUqSIJk6cmKHPdM6cOWrSpIkKFSokNzc3VaxYUbNmzbLp07p1a5UuXTrN94eFhalGjRo2bZ9//rlCQ0Pl4eGhfPnyqWvXrvrzzz9TvXfLli1q2bKl/P395enpqSpVqmjq1Kl3jPf2Z/Xzzz+rf//+yp8/v3x8fNSzZ09dunQpVf+MfIYZ/Vr+9NNPslgsmj9/vkaOHKkiRYoob968unLlSobv58CBA3r88ceVL18+ubu7q0aNGlq+fHma97hhwwZFRkaqYMGC8vT0VPv27XXu3DmbuPfu3av169db/564He/Fixc1bNgwVa5cWV5eXvLx8VGLFi20a9euVPd58uRJtW3bVp6enipUqJCGDh2qNWvWyGKx6KeffrLpu2XLFjVv3ly+vr7KmzevGjVqpA0bNtj0uXr1qoYMGWL9OS1UqJAeffRR7dixI9W1gZwqT3YHgJytZMmSCgsL05dffqkWLVpI+ifBiYuLU9euXTVt2rRU75k6daratm2rHj16KCkpSfPnz1enTp30zTffqFWrVpKkzz77TE8//bRq1aqlZ555RpJUpkwZm3E6deqk4OBgjRs3ToZhpBvjmDFjNHr0aNWtW1evv/66XF1dtWXLFv3www9q1qyZ9Xq9evVSRESEJkyYoOvXr2vWrFmqX7++du7cqZIlS6Y7fkxMjBo3bqxbt27p1Vdflaenpz744AN5eHik6ns/14mPj1eDBg20f/9+PfXUU6pevbrOnz+v5cuX66+//lKBAgV048YNPfLIIzpy5IgGDhyoUqVKaeHCherdu7cuX76swYMH24w5b948Xb16Vf3795fFYtHEiRPVoUMHHTt2TC4uLhoxYoTKly+vDz74QK+//rpKlSqV6utwN7Nnz9YLL7ygxx9/XIMHD1ZCQoL++OMPbdmyJd1/JEj/JPNjxoxReHi4nnvuOR08eFCzZs3S1q1btWHDBptp6EuXLql58+bq0KGDOnfurEWLFumVV15R5cqVrd+X6Zk1a5YqVaqktm3bKk+ePFqxYoWef/55paSkaMCAAZKkLl26qGfPntq6datq1qxpfe/Jkye1efNmTZo0ydr25ptvatSoUercubOefvppnTt3Tu+++64aNmyonTt3Wiup3333nVq3bq2goCANHjxYgYGB2r9/v7755ptUX6e0DBw4UH5+fho9erT1szl58qQ1SbP3M7THG2+8IVdXVw0bNkyJiYlydXXN0P3s3btX9erVU5EiRaw/K1999ZXatWunxYsXq3379jbXGTRokPz9/RUVFaUTJ05oypQpGjhwoBYsWCBJmjJligYNGiQvLy+NGDFCkhQQECBJOnbsmJYtW6ZOnTqpVKlSio2N1fvvv69GjRpp3759Kly4sKR/Zg+aNGmiM2fOWOOeN2+efvzxx1T3/cMPP6hFixYKDQ1VVFSUnJycrP+A+OWXX1SrVi1J0rPPPqtFixZp4MCBqlixoi5cuKBff/1V+/fvV/Xq1e/pMweynAGkYc6cOYYkY+vWrcb06dMNb29v4/r164ZhGEanTp2Mxo0bG4ZhGCVKlDBatWpl897b/W5LSkoyHnroIaNJkyY27Z6enkavXr1SXTsqKsqQZHTr1i3dc7cdPnzYcHJyMtq3b28kJyfb9E1JSTEMwzCuXr1q+Pn5Gf369bM5HxMTY/j6+qZq/68hQ4YYkowtW7ZY286ePWv4+voakozjx49nynVee+01Q5KxZMmSVOdu38uUKVMMScbnn39uPZeUlGSEhYUZXl5expUrVwzDMIzjx48bkoz8+fMbFy9etPb9+uuvDUnGihUrrG3//lr/W4kSJdL8+jRq1Mho1KiR9fVjjz1mVKpU6Y73dvsatz+rs2fPGq6urkazZs1svm7Tp083JBkff/yxzfUkGZ9++qm1LTEx0QgMDDQ6dux4x+saRurvR8MwjIiICKN06dLW13FxcYabm5vx4osv2vSbOHGiYbFYjJMnTxqGYRgnTpwwnJ2djTfffNOm3+7du408efJY22/dumWUKlXKKFGihHHp0iWbvre/lum5/VmFhoYaSUlJNrFIMr7++mvDMOz7DDP6tfzxxx8NSUbp0qVtPreM3k/Tpk2NypUrGwkJCTbn69atawQHB6e6x/DwcJv3Dx061HB2djYuX75sbatUqZJNjLclJCSk+pk/fvy44ebmZrz++uvWtrffftuQZCxbtszaduPGDSMkJMSQZPz444/WOIODg42IiAibmK5fv26UKlXKePTRR61tvr6+xoABA1LFBDxImALGXXXu3Fk3btzQN998o6tXr+qbb765Y2Xn35WxS5cuKS4uTg0aNLB7euTZZ5+9a59ly5YpJSVFr732mpycbL+db1dJvvvuO12+fFndunXT+fPnrYezs7Nq166dZiXg31auXKk6depY//UvSQULFlSPHj1s+t3vdRYvXqyqVaumqpL8+15WrlypwMBAdevWzXrOxcVFL7zwguLj47V+/Xqb93Xp0kX+/v7W1w0aNJD0T/Uks/j5+emvv/6ymVq+m++//15JSUkaMmSIzdetX79+8vHx0bfffmvT38vLS0888YT1taurq2rVqpWh+/j392NcXJzOnz+vRo0a6dixY4qLi5Mk6/ThV199ZVNtXrBggerUqaPixYtLkpYsWaKUlBR17tzZ5mscGBio4OBg69d4586dOn78uIYMGZJqbWVG10E+88wzNhW85557Tnny5NHKlSsl2f8Z2qNXr142n1tG7ufixYv64Ycf1LlzZ129etX62Vy4cEERERE6fPiw/v7771T3+O/Po0GDBkpOTtbJkyfvGqObm5v1vpOTk3XhwgV5eXmpfPnyNn/XrF69WkWKFFHbtm2tbe7u7urXr5/NeL///rsOHz6s7t2768KFC9b4r127pqZNm+rnn3+2Lvvw8/PTli1bdPr06bvGCeRUTAHjrgoWLKjw8HDNmzdP169fV3Jysh5//PF0+3/zzTcaO3asfv/9dyUmJlrb7X0AoFSpUnftc/ToUTk5OalixYrp9jl8+LAkqUmTJmme9/HxueM1Tp48qdq1a6dqL1++fKZe5+jRo+rYseNdYwkODk6V7FaoUMF6/t9uJy633U4G01pLdq9eeeUVff/996pVq5bKli2rZs2aqXv37qpXr16677kd538/Q1dXV5UuXTrVfRQtWjTV94+/v7/++OOPu8a3YcMGRUVFadOmTbp+/brNubi4OPn6+kr6J1letmyZNm3apLp16+ro0aPavn27pkyZYu1/+PBhGYah4ODgNK91O2E7evSoJOmhhx66a3zp+e81vLy8FBQUZF1Hae9naI///uxl5H6OHDkiwzA0atQojRo1Ks0+Z8+eVZEiRayv7+f7MyUlRVOnTtXMmTN1/PhxJScnW8/lz5/f+ueTJ0+qTJkyqb5/ypYta/P69s/v7TWxaYmLi5O/v78mTpyoXr16qVixYgoNDVXLli3Vs2fPdNeRAjkRCSAypHv37urXr59iYmLUokWLdJ8Y/eWXX9S2bVs1bNhQM2fOVFBQkFxcXDRnzpw0t5O5k7TW2N2L2/9q/+yzz9J8ajlPnsz5Mciq69jD2dk5zXbjDmsqb0svYU9OTrYZt0KFCjp48KC++eYbrV69WosXL9bMmTP12muvacyYMfcW+H/c630cPXpUTZs2VUhIiN555x0VK1ZMrq6uWrlypSZPnmzzIE+bNm2UN29effXVV6pbt66++uorOTk5qVOnTtY+KSkpslgsWrVqVZoxeXl53eMdOlZGv5a33cvP3u3PctiwYYqIiEizz3+Trvv5/hw3bpxGjRqlp556Sm+88Yby5csnJycnDRky5J6eWr79nkmTJqlatWpp9rn99e3cubMaNGigpUuXau3atZo0aZImTJigJUuW3HVNKpBTkAAiQ9q3b6/+/ftr8+bN1gXaaVm8eLHc3d21Zs0amz0C58yZk6pvZmwJUqZMGaWkpGjfvn3p/qV9+6GGQoUKKTw83O5rlChRwlod+LeDBw9m6nXKlCmjPXv23DWWP/74QykpKTZVwAMHDljPZxZ/f/80fyPIyZMnU1U6PD091aVLF3Xp0kVJSUnq0KGD3nzzTQ0fPjzNbXtux3nw4EGbsZKSknT8+PF7+vzSsmLFCiUmJmr58uU21aa0puM9PT3VunVrLVy4UO+8844WLFigBg0aWB8mkP75GhmGoVKlSqlcuXLpXvf298KePXvu+V4OHz6sxo0bW1/Hx8frzJkzatmypST7PkN7vpb3ej+3x3Fxccm0r5+U/t8TixYtUuPGjfXRRx/ZtF++fFkFChSwvi5RooT27dsnwzBsxjpy5IjN+27fo4+PT4biDwoK0vPPP6/nn39eZ8+eVfXq1fXmm2+SAOKBwRpAZIiXl5dmzZql0aNHq02bNun2c3Z2lsVisZmOOXHiRJobPnt6et73rxxr166dnJyc9Prrr6f6V//tKkJERIR8fHw0btw43bx5M9UY/952Ii0tW7bU5s2b9dtvv9m854svvrDpd7/X6dixo3bt2qWlS5emOnf7Xlq2bKmYmBibJPzWrVt699135eXlpUaNGt3xGvYoU6aMNm/erKSkJGvbN998k2q7kwsXLti8dnV1VcWKFWUYRpqfgySFh4fL1dVV06ZNs6n2fPTRR4qLi7M+LX6/bleY/n2NuLi4NP9BIv0zDXz69Gl9+OGH2rVrl7p06WJzvkOHDnJ2dtaYMWNSVakMw7B+FtWrV1epUqU0ZcqUVN/jGaluSdIHH3xg8/nNmjVLt27dsiYY9nyGGf1apicj91OoUCE98sgjev/993XmzJlUY9zt+z896f094ezsnOqzXLhwYap1hhEREfr7779ttqJJSEjQ7NmzbfqFhoaqTJkyeuuttxQfH59u/MnJyda1o7cVKlRIhQsXtlnyAuR0VACRYXdaG3Nbq1at9M4776h58+bq3r27zp49qxkzZqhs2bKp1muFhobq+++/1zvvvKPChQurVKlSaa61u5OyZctqxIgReuONN9SgQQN16NBBbm5u2rp1qwoXLqzo6Gj5+Pho1qxZevLJJ1W9enV17dpVBQsW1KlTp/Ttt9+qXr16mj59errXePnll/XZZ5+pefPmGjx4sHUbmNvVuNvu9zovvfSSFi1apE6dOumpp55SaGioLl68qOXLl+u9995T1apV9cwzz+j9999X7969tX37dpUsWVKLFi3Shg0bNGXKFHl7e9v1+d3J008/rUWLFql58+bq3Lmzjh49qs8//zzVNjHNmjVTYGCg6tWrp4CAAO3fv1/Tp09Xq1at0o2nYMGCGj58uMaMGaPmzZurbdu2OnjwoGbOnKmaNWvaPPBxP5o1ayZXV1e1adNG/fv3V3x8vGbPnq1ChQqlmaS0bNlS3t7eGjZsmJydnVOtySxTpozGjh2r4cOH68SJE2rXrp28vb11/PhxLV26VM8884yGDRsmJycnzZo1S23atFG1atXUp08fBQUF6cCBA9q7d6/WrFlz19iTkpLUtGlTde7c2frZ1K9f3/owgz2fYUa/lunJ6P3MmDFD9evXV+XKldWvXz+VLl1asbGx2rRpk/7666809+i7m9DQUM2aNUtjx45V2bJlVahQITVp0kStW7fW66+/rj59+qhu3bravXu3vvjii1QVzf79+2v69Onq1q2bBg8erKCgIH3xxRfWyvTtqqCTk5M+/PBDtWjRQpUqVVKfPn1UpEgR/f333/rxxx/l4+OjFStW6OrVqypatKgef/xxVa1aVV5eXvr++++1detWvf3223bfH5BtsvipYzwg0tsa5L/S2gbmo48+MoKDgw03NzcjJCTEmDNnTqrtWwzDMA4cOGA0bNjQ8PDwMCRZt6m43ffcuXOprpfWOIZhGB9//LHx8MMPG25uboa/v7/RqFEj47vvvrPp8+OPPxoRERGGr6+v4e7ubpQpU8bo3bu3sW3btrt+Hn/88YfRqFEjw93d3ShSpIjxxhtvGB999JHN1iaZcZ0LFy4YAwcONIoUKWK4uroaRYsWNXr16mWcP3/e2ic2Ntbo06ePUaBAAcPV1dWoXLmyMWfOHJtxbm8DM2nSpFTXkGRERUVZX9/pa/32228bRYoUMdzc3Ix69eoZ27ZtS7V1yPvvv280bNjQyJ8/v+Hm5maUKVPGeOmll4y4uLhU1/jvZzV9+nQjJCTEcHFxMQICAoznnnsu1TYjjRo1SnObmV69ehklSpRI/SH+x/Lly40qVaoY7u7uRsmSJY0JEyYYH3/8cZrxGIZh9OjRw7pFSXoWL15s1K9f3/D09DQ8PT2NkJAQY8CAAcbBgwdt+v3666/Go48+anh7exuenp5GlSpVjHffffeO8d7+rNavX28888wzhr+/v+Hl5WX06NHDuHDhQqr+GfkMDSNjX8vb28AsXLgwzdgycj9Hjx41evbsaQQGBhouLi5GkSJFjNatWxuLFi1KdY///Z67ff3bW7MYxj/bKLVq1crw9vY2JFnjTUhIMF588UUjKCjI8PDwMOrVq2ds2rQp1T0ZhmEcO3bMaNWqleHh4WEULFjQePHFF43FixcbkozNmzfb9N25c6fRoUMH6/dziRIljM6dOxvr1q0zDOOfLYheeuklo2rVqtbPoWrVqsbMmTPT/MyAnMpiGBmcjwAAONzcuXPVp08fbd26NdVvIEHmmTJlioYOHaq//vrL5slkwCxYAwgAyNVu3Lhh8zohIUHvv/++goODSf5gWqwBBADkah06dFDx4sVVrVo1xcXF6fPPP9eBAwdSPcgFmAkJIAAgV4uIiNCHH36oL774QsnJyapYsaLmz5+f6ilvwExYAwgAAGAyrAEEAAAwGRJAAAAAkyEBBAAAMJlc+RCIR7NJ2R0CAAc5vmhIdocAwEECfVyy7doeDw902Ng3dqb/W6CyCxVAAAAAk8mVFUAAAAC7WMxVEzPX3QIAAIAKIAAAgCyW7I4gS1EBBAAAMBkqgAAAACZbA0gCCAAAwBQwAAAAcjMqgAAAACabAjbX3QIAAIAKIAAAAGsAAQAAkKtRAQQAAGANIAAAAHIzKoAAAAAmWwNIAggAAMAUMAAAAHIzKoAAAAAmmwKmAggAAGAyVAABAABYAwgAAIDcjAogAAAAawABAACQHZKTkzVq1CiVKlVKHh4eKlOmjN544w0ZhmHtYxiGXnvtNQUFBcnDw0Ph4eE6fPiwXdchAQQAALA4Oe6ww4QJEzRr1ixNnz5d+/fv14QJEzRx4kS9++671j4TJ07UtGnT9N5772nLli3y9PRURESEEhISMnwdpoABAAByyEMgGzdu1GOPPaZWrVpJkkqWLKkvv/xSv/32m6R/qn9TpkzRyJEj9dhjj0mSPv30UwUEBGjZsmXq2rVrhq6TM+4WAAAgl0pMTNSVK1dsjsTExDT71q1bV+vWrdOhQ4ckSbt27dKvv/6qFi1aSJKOHz+umJgYhYeHW9/j6+ur2rVra9OmTRmOiQQQAADAyeKwIzo6Wr6+vjZHdHR0mmG8+uqr6tq1q0JCQuTi4qKHH35YQ4YMUY8ePSRJMTExkqSAgACb9wUEBFjPZQRTwAAAAA40fPhwRUZG2rS5ubml2ferr77SF198oXnz5qlSpUr6/fffNWTIEBUuXFi9evXKtJhIAAEAABy4BtDNzS3dhO+/XnrpJWsVUJIqV66skydPKjo6Wr169VJgYKAkKTY2VkFBQdb3xcbGqlq1ahmOiSlgAACAHOL69etycrJNz5ydnZWSkiJJKlWqlAIDA7Vu3Trr+StXrmjLli0KCwvL8HWoAAIAAOSQjaDbtGmjN998U8WLF1elSpW0c+dOvfPOO3rqqackSRaLRUOGDNHYsWMVHBysUqVKadSoUSpcuLDatWuX4euQAAIAAOQQ7777rkaNGqXnn39eZ8+eVeHChdW/f3+99tpr1j4vv/yyrl27pmeeeUaXL19W/fr1tXr1arm7u2f4Ohbj31tL5xIezSZldwgAHOT4oiHZHQIABwn0ccm2a3uEj3fY2De+f9VhY98r1gACAACYDFPAAAAAOWQNYFYhAQQAAMghvwouq5jrbgEAAEAFEAAAwGxTwFQAAQAATIYKIAAAAGsAAQAAkJtRAQQAAGANIAAAAHIzKoAAAAAmWwNIAggAAMAUMAAAAHIzKoAAAAAmmwI2190CAACACiAAAAAVQAAAAORqVAABAAB4ChgAAAC5GRVAAAAAk60BJAEEAABgChgAAAC5GRVAAAAAk00Bm+tuAQAAQAUQAACANYAAAADI1agAAgAA07NQAQQAAEBuRgUQAACYntkqgCSAAAAA5sr/mAIGAAAwGyqAAADA9Mw2BUwFEAAAwGSoAAIAANOjAggAAIBcjQogAAAwPSqAAAAAyNWoAAIAANMzWwWQBBAAAMBc+R9TwAAAAGZDBRAAAJie2aaAqQACAACYDBVAAABgelQAAQAAkKtRAQQAAKZHBRAAAAC5GhVAAABgemarAJIAAgAAmCv/YwoYAADAbKgAAgAA0zPbFDAVQAAAAJOhAggAAEyPCiAAAAByNSqAAADA9KgAAgAAIFejAggAAGCuAiAJIAAAAFPAAAAAyBYlS5aUxWJJdQwYMECSlJCQoAEDBih//vzy8vJSx44dFRsba/d1SAABAIDppZV0ZdZhj61bt+rMmTPW47vvvpMkderUSZI0dOhQrVixQgsXLtT69et1+vRpdejQwe77ZQoYAAAghyhYsKDN6/Hjx6tMmTJq1KiR4uLi9NFHH2nevHlq0qSJJGnOnDmqUKGCNm/erDp16mT4OlQAAQCA6TmyApiYmKgrV67YHImJiXeNKSkpSZ9//rmeeuopWSwWbd++XTdv3lR4eLi1T0hIiIoXL65NmzbZdb8kgAAAAA4UHR0tX19fmyM6Ovqu71u2bJkuX76s3r17S5JiYmLk6uoqPz8/m34BAQGKiYmxKyamgAEAgOk58ing4cOHKzIy0qbNzc3tru/76KOP1KJFCxUuXDjTYyIBBAAAcCA3N7cMJXz/dvLkSX3//fdasmSJtS0wMFBJSUm6fPmyTRUwNjZWgYGBdo3PFDAAAIDFgcc9mDNnjgoVKqRWrVpZ20JDQ+Xi4qJ169ZZ2w4ePKhTp04pLCzMrvGpAAIAANPLSRtBp6SkaM6cOerVq5fy5Pm/VM3X11d9+/ZVZGSk8uXLJx8fHw0aNEhhYWF2PQEskQACAADkKN9//71OnTqlp556KtW5yZMny8nJSR07dlRiYqIiIiI0c+ZMu69BAggAAEwvJ1UAmzVrJsMw0jzn7u6uGTNmaMaMGfd1DdYAAgAAmAwVQAAAYHo5qQKYFagAAgAAmAwVQAAAAHMVAKkAAgAAmA0VQAAAYHqsAQQAAECuRgUQAACYntkqgCSAyDYHPn1GJQJ9U7W/t3ynhk7/XgH+nhrXr5GaVC8p77wuOvTnJU38crOW/Xoo3TFHPFlXI5+sZ9N28M8Lqtb3Y0mSv7e7Rj1ZT01DS6pYIW+dj7uhFRsPa8zcX3XlelLm3iBgUp/Pma2ff/xep04el5ubux6qUk39Bw5V8ZKlrH2WL1modWu+1aGD+3X92jV988NGeXv7ZPgaX8z9UB/MmKLHuz6hQS++am2/cP68Zk17S9u3bNL169dVrERJPfnUM2rU5NFMvUfkPiSAQBapP+gzOTv93yqEiiULaOWEzlry80FJ0ocvt5Sfp5s6RS3R+bgb6tKkgj4f0Ub1Bn6mXUfPpjvu3hPn1OqVhdbXt5JTrH8Oyu+loPxeGj77J+0/eUHFA3z07guPKii/l7q/sdwBdwmYz64d29S+UzeFVHxIycm3NHvmVA0b9Iw++epreXjklSQlJiSoVlh91Qqrrw9mTLFr/P17d2v50oUqE1wu1blxo4cr/upVjXtnunx9/fT9mpUaPfxFvf/pApUrXyEzbg/IFVgDiGxzPu6GYi9dsx4ta5fW0b8v6Zc//pQk1alYWDO/3qFtB2N0IiZOE+Zt1uVriXo4OOCO495KNmzGvXDlhvXcvhPn1e2Nr7Vy81EdP3NZ638/pdFzflHL2mXk7GSuf/0BjjLp3ffVok07lSpTVmXLhWh41JuKjTmjQ/v3Wft06v6kevR+WhUrV7Fr7OvXr2vsa6/qpf+NTrNiuPeP39WhS3dVqFRZhYsWU8++/eXl7a1D+/fe930hd7NYLA47cqJsTQDPnz+viRMnqn379goLC1NYWJjat2+vSZMm6dy5c9kZGrKYSx4ndW1aUZ+s2W1t27zvtB5vFCJ/b3dZLFKnR0Lk7uqsn/9/gpieskX8dOzL57Tvk36a82orFSvofcf+Pp5uunI9Sckpaf/eRQD3Jz4+XpLk7ZN6yYe9pkwcq7B6DVWjdlia5ytVqaYfv1utK3FxSklJ0bq1K5WUmKRqobXu+9pAbpJtU8Bbt25VRESE8ubNq/DwcJUr908pPzY2VtOmTdP48eO1Zs0a1ahRI7tCRBZqWzdYfl7u+nztHmvbE2OX67MRbXR68SDdvJWs64m31GXM1zp2+nK642w9cEbPTFqlQ39dUmA+T414oq6+f6ebQp+Zo/gbN1P1z+/joeE9wvTxyl2OuC3A9FJSUjT9nfGqXPVhlS4bfF9jrVu7UocO7Nf7n8xPt8/o6Lc15n/D1Ca8npyd88jd3V1jJ01R0WLF7+vaMIGcWahzmGxLAAcNGqROnTrpvffeS1UeNQxDzz77rAYNGqRNmzbdcZzExEQlJibavj/llixOLG98kPRqXllrth7TmYvXrG1RverLz8tNLV5eoAtXbqhN3WB9PqKNwiO/1N4T59McZ+3W49Y/7zl+TlsPnNHBz/urY6MQfbJ6t01f77yuWjq2g/afuqCxn210zI0BJjd54lgdP3pE787+9L7GORtzRu++PV5vT58tNze3dPt99N50xV+9qndmfChfPz/9uv4HjR4+TNNmf6IyZVOvGQTMKtuypF27dmnu3Llpzo1bLBYNHTpUDz/88F3HiY6O1pgxY2zanEuHy6VMs0yLFY5VvJCPmjxcQl1f/9raVirIT8+1q67q/T7W/pMXJEm7j51TvYeKqn/bh/XCtO8yNHbctUQd+euiyhT2s2n38nDR8jcf19XrN9Vl9DKbB0UAZI4pE9/Upl/W690PPlGhgMD7GuvggX26dPGi+j3Z2dqWnJysXTu3a+nCL/Xdhh2KOfO3ln41T3PnL1OpMmUlSWXLheiPnTu0bOGXenF41H3FgNwtp67Vc5RsSwADAwP122+/KSQkJM3zv/32mwIC7rzYX5KGDx+uyMhIm7ZCHWZkSozIGk9GPKSzl69r1Zaj1ra8bv98a6b8Z11eckqKnOx4WMPT3UWlgvwUs+7/Fp9753XVinGdlHjzlh6PWqLEm8n3eQcA/s0wDE2dNE6//LROU9+bo6AiRe97zNCadTTny6U2beNfH6niJUupe8++cnZ2VkJCgiTJ8p+/I5ycnVL9XQKYXbYlgMOGDdMzzzyj7du3q2nTptZkLzY2VuvWrdPs2bP11ltv3XUcNze3VNMBTP8+OCwWqWezh/TFd3ttHsI4+OdFHfn7kqYPaabhH/ykC1cS1LZuWTWtXlIdRi229ls5obOWbzis95bvlCRF93tE324+olNnr6hwfi+N7FlPySmGvvpxv6R/kr9vojvJw81FfSZ8K5+8bvLJ+8/3z7m46/xPAsgEkyeM1bo1K/XmW9PkkddTF87/s2TDy8tLbu7ukv7Zr+/ihfP6+89TkqRjRw4rb15PBQQGycf3n4dFhj7XVw0aN1WHzt2V19Mz1RpCDw8P+fr6WdtLlCylIsWK6+3o1/X84GHy8fXVrz/9oG1bNmn8ZAoDuDMqgFlkwIABKlCggCZPnqyZM2cqOfmfKoyzs7NCQ0M1d+5cde7c+S6j4EHXpHpJFQ/wtXn6V/pn7752IxZpbN9GWvR6B3l5uOjo35f19KSVWvOvdX6lg/yU39fD+rpIQS99+r82yuftrvNxN7Rx719qNPgLnY/7ZyuYamUDVKtCYUnSvk/62Vyz/JPv61TsFUfdKmAaXy9eIEka/Gwfm/ZXXxurFm3aSZKWL1mgubNnWc+98EyvVH1O//2n4i5fyvB18+Rx0cQps/T+9MkaHjlAN67fUJFixTR89JuqU6/hfdwRzMBk+Z8shmFke8nj5s2bOv///4VYoEABubi43Nd4Hs0mZUZYAHKg44uGZHcIABwk0Of+/v9/P8oOW+WwsY+81cJhY9+rHDFX6uLioqCgoOwOAwAAmJTZpoD5TSAAAAAmkyMqgAAAANnJZAVAKoAAAABmQwUQAACYHmsAAQAAkKtRAQQAAKZnsgIgCSAAAIA9v2Y0N2AKGAAAwGSoAAIAANMz2xQwFUAAAACToQIIAABMj21gAAAAkKtRAQQAAKZnsgIgFUAAAACzoQIIAABMz2xrAEkAAQCA6ZktAWQKGAAAwGSoAAIAANMzWQGQCiAAAIDZUAEEAACmxxpAAAAA5GpUAAEAgOmZrABIBRAAAMBsqAACAADTM9saQBJAAABgeibL/5gCBgAAMBsqgAAAwPTMNgVMBRAAAMBkqAACAADTM1kBkAogAACA2VABBAAApscaQAAAAORqVAABAIDpmawASAIIAADAFDAAAAByNSqAAADA9ExWAKQCCAAAYDYkgAAAwPQsFovDDnv9/fffeuKJJ5Q/f355eHiocuXK2rZtm/W8YRh67bXXFBQUJA8PD4WHh+vw4cN2XYMEEAAAIIe4dOmS6tWrJxcXF61atUr79u3T22+/LX9/f2ufiRMnatq0aXrvvfe0ZcsWeXp6KiIiQgkJCRm+DmsAAQCA6eWUNYATJkxQsWLFNGfOHGtbqVKlrH82DENTpkzRyJEj9dhjj0mSPv30UwUEBGjZsmXq2rVrhq5DBRAAAMCBEhMTdeXKFZsjMTExzb7Lly9XjRo11KlTJxUqVEgPP/ywZs+ebT1//PhxxcTEKDw83Nrm6+ur2rVra9OmTRmOiQQQAACYniPXAEZHR8vX19fmiI6OTjOOY8eOadasWQoODtaaNWv03HPP6YUXXtAnn3wiSYqJiZEkBQQE2LwvICDAei4jmAIGAACm58iNoIcPH67IyEibNjc3tzT7pqSkqEaNGho3bpwk6eGHH9aePXv03nvvqVevXpkWExVAAAAAB3Jzc5OPj4/NkV4CGBQUpIoVK9q0VahQQadOnZIkBQYGSpJiY2Nt+sTGxlrPZQQJIAAAMD2LxXGHPerVq6eDBw/atB06dEglSpSQ9M8DIYGBgVq3bp31/JUrV7RlyxaFhYVl+DpMAQMAAOQQQ4cOVd26dTVu3Dh17txZv/32mz744AN98MEHkv6Zqh4yZIjGjh2r4OBglSpVSqNGjVLhwoXVrl27DF+HBBAAAJieI9cA2qNmzZpaunSphg8frtdff12lSpXSlClT1KNHD2ufl19+WdeuXdMzzzyjy5cvq379+lq9erXc3d0zfB2LYRiGI24gO3k0m5TdIQBwkOOLhmR3CAAcJNDHJduu/ciUjQ4b+6chdR029r2iAggAAEwvhxQAswwPgQAAAJgMFUAAAGB6OWUNYFYhAQQAAKZnsvyPKWAAAACzoQIIAABMz8lkJUAqgAAAACZDBRAAAJieyQqAVAABAADMhgogAAAwPbNtA0MFEAAAwGSoAAIAANNzMlcBkAQQAACAKWAAAADkalQAAQCA6ZmsAEgFEAAAwGyoAAIAANOzyFwlQCqAAAAAJnNPCeCtW7f0/fff6/3339fVq1clSadPn1Z8fHymBgcAAJAVnCyOO3Iiu6eAT548qebNm+vUqVNKTEzUo48+Km9vb02YMEGJiYl67733HBEnAAAAMondFcDBgwerRo0aunTpkjw8PKzt7du317p16zI1OAAAgKxgsVgcduREdlcAf/nlF23cuFGurq427SVLltTff/+daYEBAADAMexOAFNSUpScnJyq/a+//pK3t3emBAUAAJCVcmihzmHsngJu1qyZpkyZYn1tsVgUHx+vqKgotWzZMjNjAwAAyBJOFovDjpzI7grg22+/rYiICFWsWFEJCQnq3r27Dh8+rAIFCujLL790RIwAAADIRHYngEWLFtWuXbs0f/58/fHHH4qPj1ffvn3Vo0cPm4dCAAAAHhQ5tFDnMPf0m0Dy5MmjJ554IrNjAQAAQBbIUAK4fPnyDA/Ytm3bew4GAAAgO+TU7VocJUMJYLt27TI0mMViSfMJYQAAAOQcGUoAU1JSHB0HAABAtjFZAfDefhcwAAAAHlwZqgBOmzYtwwO+8MIL9xwMAABAdsip+/U5SoYSwMmTJ2doMIvFQgIIAAAeOOZK/zKYAB4/ftzRcQAAACCL3PMawKSkJB08eFC3bt3KzHgAAACynMVicdiRE9mdAF6/fl19+/ZV3rx5ValSJZ06dUqSNGjQII0fPz7TAwQAAEDmsjsBHD58uHbt2qWffvpJ7u7u1vbw8HAtWLAgU4MDAADICk4Wxx05kd2/Cm7ZsmVasGCB6tSpY1PWrFSpko4ePZqpwQEAACDz2Z0Anjt3ToUKFUrVfu3atRw7zw0AAHAnZsth7J4CrlGjhr799lvr69sf2IcffqiwsLDMiwwAAAAOYXcFcNy4cWrRooX27dunW7duaerUqdq3b582btyo9evXOyJGAAAAhzJZAdD+CmD9+vX1+++/69atW6pcubLWrl2rQoUKadOmTQoNDXVEjAAAAA5ltm1g7K4ASlKZMmU0e/bszI4FAAAAWeCeNoI+evSoRo4cqe7du+vs2bOSpFWrVmnv3r2ZGhwAAEBWMNs2MHdNAA8ePGjzev369apcubK2bNmixYsXKz4+XpK0a9cuRUVFOSZKAAAAZJq7JoBLlixRjx49lJycLEl69dVXNXbsWH333XdydXW19mvSpIk2b97suEgBAAAcxGxrAO+aAA4bNkz58uVTRESEJGn37t1q3759qn6FChXS+fPnMz9CAAAAZKq7JoAuLi5699131b9/f0mSn5+fzpw5k6rfzp07VaRIkcyPEAAAwMEsDjxyogw/BNKpUydJUteuXfXKK68oJiZGFotFKSkp2rBhg4YNG6aePXs6LFAAAABkDrufAh43bpxCQkJUrFgxxcfHq2LFimrYsKHq1q2rkSNHOiJGAAAAh3KyWBx25ER27QNoGIZiYmI0bdo0vfbaa9q9e7fi4+P18MMPKzg42FExAgAAOFQOzdMcxu4EsGzZstq7d6+Cg4NVrFgxR8UFAAAAB7FrCtjJyUnBwcG6cOGCo+IBAADIcmwDcxfjx4/XSy+9pD179jgiHgAAADiY3b8LuGfPnrp+/bqqVq0qV1dXeXh42Jy/ePFipgUHAACQFXJooc5h7E4Ap0yZ4oAwAAAAkFXsTgB79erliDgAAACyTU7drsVR7F4DCAAAAMcYPXp0qodIQkJCrOcTEhI0YMAA5c+fX15eXurYsaNiY2Ptvg4JIAAAMD2LxXGHvSpVqqQzZ85Yj19//dV6bujQoVqxYoUWLlyo9evX6/Tp0+rQoYPd17B7ChgAACC3yUnbteTJk0eBgYGp2uPi4vTRRx9p3rx5atKkiSRpzpw5qlChgjZv3qw6depk+BpUAAEAABwoMTFRV65csTkSExPT7X/48GEVLlxYpUuXVo8ePXTq1ClJ0vbt23Xz5k2Fh4db+4aEhKh48eLatGmTXTHdcwXwyJEjOnr0qBo2bCgPDw8ZhpFjsudLK1/K7hAAOIh/zYHZHQIAB7mxc3q2XduRFbHo6GiNGTPGpi0qKkqjR49O1bd27dqaO3euypcvrzNnzmjMmDFq0KCB9uzZo5iYGLm6usrPz8/mPQEBAYqJibErJrsTwAsXLqhLly764YcfZLFYdPjwYZUuXVp9+/aVv7+/3n77bXuHBAAAyLWGDx+uyMhImzY3N7c0+7Zo0cL65ypVqqh27doqUaKEvvrqq1R7L98PuxPeoUOHKk+ePDp16pTy5s1rbe/SpYtWr16daYEBAABkFUf+Kjg3Nzf5+PjYHOklgP/l5+encuXK6ciRIwoMDFRSUpIuX75s0yc2NjbNNYN3YncCuHbtWk2YMEFFixa1aQ8ODtbJkyftHQ4AAADpiI+P19GjRxUUFKTQ0FC5uLho3bp11vMHDx7UqVOnFBYWZte4dk8BX7t2zabyd9vFixcznM0CAADkJE454zEGDRs2TG3atFGJEiV0+vRpRUVFydnZWd26dZOvr6/69u2ryMhI5cuXTz4+Pho0aJDCwsLsegJYuocKYIMGDfTpp59aX1ssFqWkpGjixIlq3LixvcMBAADg//vrr7/UrVs3lS9fXp07d1b+/Pm1efNmFSxYUJI0efJktW7dWh07dlTDhg0VGBioJUuW2H0di2EYhj1v2LNnj5o2barq1avrhx9+UNu2bbV3715dvHhRGzZsUJkyZewOIrMl3MruCAA4Ck8BA7lXdj4FHLn8gMPGfqdtyN07ZTG7K4APPfSQDh06pPr16+uxxx7TtWvX1KFDB+3cuTNHJH8AAAD2cuRDIDnRPe0D6OvrqxEjRmR2LAAAAMgCdlcAV69ebfM76WbMmKFq1aqpe/fuunTpUqYGBwAAkBWcLI47ciK7E8CXXnpJV65ckSTt3r1bkZGRatmypY4fP55qk0MAAADkPHZPAR8/flwVK1aUJC1evFht2rTRuHHjtGPHDrVs2TLTAwQAAHC0HLpUz2HsrgC6urrq+vXrkqTvv/9ezZo1kyTly5fPWhkEAABAzmV3BbB+/fqKjIxUvXr19Ntvv2nBggWSpEOHDqX67SAAAAAPAieTlQDtrgBOnz5defLk0aJFizRr1iwVKVJEkrRq1So1b9480wMEAABA5rK7Ali8eHF98803qdonT56cKQEBAABkNbsrYg84u+93x44d2r17t/X1119/rXbt2ul///ufkpKSMjU4AACArGCxOO7IiexOAPv3769Dhw5Jko4dO6auXbsqb968WrhwoV5++eVMDxAAAACZy+4E8NChQ6pWrZokaeHChWrYsKHmzZunuXPnavHixZkdHwAAgMM5WSwOO3IiuxNAwzCUkpIi6Z9tYG7v/VesWDGdP38+c6MDAABAprP7IZAaNWpo7NixCg8P1/r16zVr1ixJ/2wQHRAQkOkBAgAAOFoOLdQ5jN0VwClTpmjHjh0aOHCgRowYobJly0qSFi1apLp162Z6gAAAAMhcdlcAq1SpYvMU8G2TJk2Ss7NzpgQFAACQlZxMVgG0OwFMj7u7e2YNBQAAAAeyOwFMTk7W5MmT9dVXX+nUqVOp9v67ePFipgUHAACQFXLq07qOYvcawDFjxuidd95Rly5dFBcXp8jISHXo0EFOTk4aPXq0A0IEAABwLDaCvosvvvhCs2fP1osvvqg8efKoW7du+vDDD/Xaa69p8+bNjogRAAAAmcjuBDAmJkaVK1eWJHl5eSkuLk6S1Lp1a3377beZGx0AAEAWcLI47siJ7E4AixYtqjNnzkiSypQpo7Vr10qStm7dKjc3t8yNDgAAAJnO7gSwffv2WrdunSRp0KBBGjVqlIKDg9WzZ0899dRTmR4gAACAo1kc+F9OZPdTwOPHj7f+uUuXLipevLg2bdqk4OBgtWnTJlODAwAAQOa7730Aw8LCFBYWlhmxAAAAZIuculbPUTKUAC5fvjzDA7Zt2/aegwEAAIDjZSgBbNeuXYYGs1gsSk5Ovp94AAAAshwVwDSkpKQ4Og4AAABkkUz7XcAAAAAPKktO/ZUdDpLhbWB++OEHVaxYUVeuXEl1Li4uTpUqVdLPP/+cqcEBAABkBTaCTseUKVPUr18/+fj4pDrn6+ur/v37a/LkyZkaHAAAADJfhhPAXbt2qXnz5umeb9asmbZv354pQQEAAGQli8VxR06U4QQwNjZWLi4u6Z7PkyePzp07lylBAQAAwHEynAAWKVJEe/bsSff8H3/8oaCgoEwJCgAAICs5WSwOO3KiDCeALVu21KhRo5SQkJDq3I0bNxQVFaXWrVtnanAAAADIfBneBmbkyJFasmSJypUrp4EDB6p8+fKSpAMHDmjGjBlKTk7WiBEjHBYoAACAo+TUp3UdJcMJYEBAgDZu3KjnnntOw4cPl2EYkv7ZNyciIkIzZsxQQECAwwIFAABA5rBrI+gSJUpo5cqVunTpko4cOSLDMBQcHCx/f39HxQcAAOBwOXSpnsPc028C8ff3V82aNTM7FgAAgGzhJHNlgBl+CAQAAAC5A78LGAAAmJ7ZpoCpAAIAAJgMFUAAAGB6ZtsGhgogAACAyVABBAAAppdTf2Wbo1ABBAAAMBkqgAAAwPRMVgAkAQQAAGAKGAAAALkaFUAAAGB6JisAUgEEAAAwGyqAAADA9MxWETPb/QIAAJgeFUAAAGB6FpMtAqQCCAAAYDJUAAEAgOmZq/5HAggAAMBG0AAAAMgZxo8fL4vFoiFDhljbEhISNGDAAOXPn19eXl7q2LGjYmNj7RqXBBAAAJiexYHHvdq6davef/99ValSxaZ96NChWrFihRYuXKj169fr9OnT6tChg11jkwACAADkMPHx8erRo4dmz54tf39/a3tcXJw++ugjvfPOO2rSpIlCQ0M1Z84cbdy4UZs3b87w+CSAAADA9CwWxx2JiYm6cuWKzZGYmHjHeAYMGKBWrVopPDzcpn379u26efOmTXtISIiKFy+uTZs2Zfh+SQABAAAcKDo6Wr6+vjZHdHR0uv3nz5+vHTt2pNknJiZGrq6u8vPzs2kPCAhQTExMhmPiKWAAAGB6jtwIevjw4YqMjLRpc3NzS7Pvn3/+qcGDB+u7776Tu7u7w2IiAQQAAHAgNze3dBO+/9q+fbvOnj2r6tWrW9uSk5P1888/a/r06VqzZo2SkpJ0+fJlmypgbGysAgMDMxwTCSAAADC9nLImrmnTptq9e7dNW58+fRQSEqJXXnlFxYoVk4uLi9atW6eOHTtKkg4ePKhTp04pLCwsw9chAQQAAKaXU34XsLe3tx566CGbNk9PT+XPn9/a3rdvX0VGRipfvnzy8fHRoEGDFBYWpjp16mT4OiSAAAAAD5DJkyfLyclJHTt2VGJioiIiIjRz5ky7xrAYhmE4KL5sk3AruyMA4Cj+NQdmdwgAHOTGzunZdu2Fv5922NidqhV22Nj3KqdMeQMAACCLMAUMAABML6esAcwqVAABAABMhgogAAAwPbNVxMx2vwAAAKZHBRAAAJie2dYAkgACAADTM1f6xxQwAACA6VABBAAApmeyGWAqgAAAAGZDBRAAAJiek8lWAVIBBAAAMBkqgAAAwPRYAwgAAIBcjQogAAAwPYvJ1gCSAAIAANNjChgAAAC5GhVAAABgemwDAwAAgFyNCiAAADA91gACAAAgV6MCCAAATI8KIAAAAHI1KoAAAMD02AgaAADAZJzMlf8xBQwAAGA2VAABAIDpmW0KmAogAACAyVABBAAApsc2MAAAAMjVqAACAADTYw0gAAAAcjUqgAAAwPTYBxAAAAC5GhVAAABgemZbA0gCiGyzfdtWzf34I+3ft0fnzp3T5Gkz1KRpuE2fY0ePaso7k7R921bdSk5WmdJl9PaUdxVUuHC6465ds0oz3p2q03//reIlSmpI5DA1aNjIer5qpfJpvm/oiy+p91NPZ87NASbm5GTRyGdbqlvLmgrI76Mz5+L02YotGj97tbXPiP4t1SmiuooG+ivpZrJ27j+l0dNXaOuek+mO65XXTVHPt1bbJlVV0N9Luw7+pWETF2n7vlP3NS4gmW8bGBJAZJsbN66rfPnyatehoyIHD0x1/s9Tp9T7ye5q36Gjnhv4grw8vXT0yGG5urmlO+bvO3fo1Zde1AtDItWwUWOt/HaFhgwaoPmLlig4uJwkad1Pv9q859dff9boUSMU/mhE5t4gYFIv9n5U/R5voH6vfaZ9R88otFJxvT/6CV2Jv6GZX66XJB05eVZDJyzU8b/Oy8PNRYOeaKIVMwfqocfG6Pyl+DTHnfVad1UsW1hPjfxEZ87FqVvLWvr2vUGq3nGsTp+Lu+dxATOyGIZhZHcQmS3hVnZHAHtVrVQ+VQXw5WFDlSdPHo0bPynD47z04hDduHFD02e+b217oltnlQ8J0aio19N8z5BBz+vatWua/fEn934DyDL+NVP/YwE5y+Kpz+rsxSt6bsw8a9uXbz2tGwlJemrkp2m+x9vTXWd/fUst+k/TT78dSnXe3c1F5359S52GfqDVv+61tm/44mWt3bBPY2Z+c0/jIme5sXN6tl17w+FLDhu7XrC/w8a+VzwEghwpJSVFv6z/SSVKlNSz/frqkQZh6tG1k35Y9/0d3/fH77+rTp0wm7a69errj99/T7P/hfPn9cvP69W+w+OZFTpgept3HVPjWuVVtnghSVLlckUUVq201m7Yl2Z/lzzO6tuhni5fva7dh/5Os08eZyflyeOshKSbNu0JiTdV9+Ey9zwuYFY5egr4zz//VFRUlD7++OPsDgVZ7OKFC7p+/bo+/mi2Bg4aoiGRw7Th118UOXigPpzzqWrUrJXm+86fP6/8+QvYtOXPn1/nL5xPs//yr5cqb15PNX20WabfA2BWb835Tj5e7tq1dKSSkw05O1sUNeMbzV+1zaZfiwYP6dPxfZTX3UUx56+o9bPTdeHytTTHjL+eqM27jml4vxY6eDxWsReuqHPzGqpdpZSO/nnunscFbnMy2SLAHF0BvHjxoj755M7TcomJibpy5YrNkZiYmEURwlFSjBRJUuPGTfVkr94KqVBBffs9o4aNHtHCBfMz7TrLli5Wy9Zt5HaHdYUA7PN4s+rq2qKmev/vE4V1n6CnX/tMQ55sqh5tatv0W7/1kGp3jVbj3u9o7cZ9+nziUyro75XuuE+N/FQWi3Rs7ZuK2zJFA7o10lertyklxXYlk73jAmaUrRXA5cuX3/H8sWPH7jpGdHS0xowZY9M2YlSURr42+n5CQzbz9/NXnjx5VLqM7dROqdJl9PuO7em+r0CBArrwn2rfhQsXVOA/VUFJ2rF9m04cP66Jb03JlJgB/GPckHZ6a853Wrjmn5/VvUdOq3hQPr3U51F9sWKLtd/1hCQd+/O8jv15Xr/tPqHdX7+mXu3r6q2P16Y57vG/zqvZ01OV191VPl7uijl/RZ+N76Pjf9v+zNs7LiDJZJvAZHMC2K5dO1ksFt3pORTLXUqyw4cPV2RkpE2b4Uw150Hn4uqqSg9V1okTx23aT548oaDCRdJ9X5Vq1bRl82Y90bO3tW3zpo2qUq1aqr5LFy9SxUqVVD4kJLPCBiDJw93VWsW/LTnFkJPTnSednCwWubnc/X9L1xOSdD0hSX7eHgqvW0EjpnydKeMCZpKtU8BBQUFasmSJUlJS0jx27Nhx1zHc3Nzk4+NjczCd92C4fu2aDuzfrwP790uS/v7rLx3Yv19nTp+WJPXq01drVq3S4oVf6dTJk/ryi8/1808/qnPXbtYxRgx/WVMnv2193eOJntq44Rd9MvdjHT92VLNmvKu9e/aoa/cnbK4dHx+vtWtXq33HTllwp4C5rPx5t17pG6Hm9SupeFA+tW1cRS880VjLf9glScrr7qoxA9uoVuWSKh7kr4crFNN7UT1UuJCflnz3f3/vr3xvkJ7t0tD6Ojysgh6tW0ElCudXk9ohWj17sA4dj9WnyzfZNS6QJosDjxwoW/9JFBoaqu3bt+uxxx5L8/zdqoN4sO3du0dP9+lpff3WxGhJUtvH2uuNcePVNPxRjYwarY9nf6AJ0WNVsmQpvT1lmqqH1rC+J+bMGTlZ/u/fMdUerq7oiW9p+rQpenfKOypeoqSmvDvDugfgbatXfisZhlq0bO3guwTMJ3LCQkU931pT/9dFBf29dOZcnD5atEHjPlglSUpOSVH5kgF6ok1t5ffz1MW469q296TCn5qs/cdirOOULlZA+f3+b+2er5e7Xh/UVkUC/HQx7rq+Xve7omas0K1bKXaNC6TFbL8JJFv3Afzll1907do1NW/ePM3z165d07Zt29SoUaM0z6eHfQCB3It9AIHcKzv3AdxyNM5hY9cu4+uwse9VtlYAGzRocMfznp6edid/AAAA9jLZLjA5exsYAAAAZD4eiwIAAKZnsgIgFUAAAACzoQIIAABgshIgFUAAAACToQIIAABMz2z7AJIAAgAA02MbGAAAAORqVAABAIDpmawASAUQAADAbEgAAQAALA487DBr1ixVqVJFPj4+8vHxUVhYmFatWmU9n5CQoAEDBih//vzy8vJSx44dFRsba/ftkgACAADkEEWLFtX48eO1fft2bdu2TU2aNNFjjz2mvXv3SpKGDh2qFStWaOHChVq/fr1Onz6tDh062H0di2EYRmYHn90SbmV3BAAcxb/mwOwOAYCD3Ng5PduuvfPkVYeN/XAJ7/t6f758+TRp0iQ9/vjjKliwoObNm6fHH39cknTgwAFVqFBBmzZtUp06dTI8JhVAAAAAB0pMTNSVK1dsjsTExLu+Lzk5WfPnz9e1a9cUFham7du36+bNmwoPD7f2CQkJUfHixbVp0ya7YiIBBAAApmexOO6Ijo6Wr6+vzREdHZ1uLLt375aXl5fc3Nz07LPPaunSpapYsaJiYmLk6uoqPz8/m/4BAQGKiYmx637ZBgYAAJieI7eBGT58uCIjI23a3Nzc0u1fvnx5/f7774qLi9OiRYvUq1cvrV+/PlNjIgEEAABwIDc3tzsmfP/l6uqqsmXLSpJCQ0O1detWTZ06VV26dFFSUpIuX75sUwWMjY1VYGCgXTExBQwAAJBDtoFJS0pKihITExUaGioXFxetW7fOeu7gwYM6deqUwsLC7BqTCiAAAEAOMXz4cLVo0ULFixfX1atXNW/ePP30009as2aNfH191bdvX0VGRipfvnzy8fHRoEGDFBYWZtcTwBIJIAAAgCw55JfBnT17Vj179tSZM2fk6+urKlWqaM2aNXr00UclSZMnT5aTk5M6duyoxMRERUREaObMmXZfh30AATxQ2AcQyL2ycx/AP/6Md9jYVYp5OWzse0UFEAAAmJ4lZxQAswwPgQAAAJgMFUAAAGB6JisAkgACAACYLQNkChgAAMBkqAACAADTyynbwGQVKoAAAAAmQwUQAACYHtvAAAAAIFejAggAAEzPZAVAKoAAAABmQwUQAADAZCVAEkAAAGB6bAMDAACAXI0KIAAAMD22gQEAAECuRgUQAACYnskKgFQAAQAAzIYKIAAAgMlKgFQAAQAATIYKIAAAMD2z7QNIAggAAEyPbWAAAACQq1EBBAAApmeyAiAVQAAAALOhAggAAGCyEiAVQAAAAJOhAggAAEzPbNvAUAEEAAAwGSqAAADA9My2DyAJIAAAMD2T5X9MAQMAAJgNFUAAAACTlQCpAAIAAJgMFUAAAGB6bAMDAACAXI0KIAAAMD2zbQNDBRAAAMBkqAACAADTM1kBkAQQAACAKWAAAADkalQAAQAATDYJTAUQAADAZKgAAgAA02MNIAAAAHI1KoAAAMD0TFYApAIIAABgNlQAAQCA6bEGEAAAALkaFUAAAGB6FpOtAiQBBAAAMFf+xxQwAACA2VABBAAApmeyAiAVQAAAALOhAggAAEyPbWAAAACQq1EBBAAApme2bWCoAAIAAOQQ0dHRqlmzpry9vVWoUCG1a9dOBw8etOmTkJCgAQMGKH/+/PLy8lLHjh0VGxtr13VIAAEAACwOPOywfv16DRgwQJs3b9Z3332nmzdvqlmzZrp27Zq1z9ChQ7VixQotXLhQ69ev1+nTp9WhQwf7btcwDMO+0HK+hFvZHQEAR/GvOTC7QwDgIDd2Ts+2a5+Pd1zyUMDr3lfcnTt3ToUKFdL69evVsGFDxcXFqWDBgpo3b54ef/xxSdKBAwdUoUIFbdq0SXXq1MnQuFQAAQAAHCgxMVFXrlyxORITEzP03ri4OElSvnz5JEnbt2/XzZs3FR4ebu0TEhKi4sWLa9OmTRmOiQQQAACYnsXiuCM6Olq+vr42R3R09F1jSklJ0ZAhQ1SvXj099NBDkqSYmBi5urrKz8/Ppm9AQIBiYmIyfL88BQwAAOBAw4cPV2RkpE2bm5vbXd83YMAA7dmzR7/++mumx0QCCAAATM+R28C4ubllKOH7t4EDB+qbb77Rzz//rKJFi1rbAwMDlZSUpMuXL9tUAWNjYxUYGJjh8ZkCBgAAyCEMw9DAgQO1dOlS/fDDDypVqpTN+dDQULm4uGjdunXWtoMHD+rUqVMKCwvL8HWoAAIAANPLKb8KbsCAAZo3b56+/vpreXt7W9f1+fr6ysPDQ76+vurbt68iIyOVL18++fj4aNCgQQoLC8vwE8ASCSAAAECOMWvWLEnSI488YtM+Z84c9e7dW5I0efJkOTk5qWPHjkpMTFRERIRmzpxp13XYBxDAA4V9AIHcKzv3Abx0PdlhY/vndXbY2PeKCiAAADC9nDIFnFV4CAQAAMBkqAACAADTc+Q2MDkRFUAAAACToQIIAABMjzWAAAAAyNWoAAIAANMzWQGQCiAAAIDZUAEEAAAwWQmQBBAAAJge28AAAAAgV6MCCAAATI9tYAAAAJCrUQEEAACmZ7ICIBVAAAAAs6ECCAAAYLISIBVAAAAAk6ECCAAATM9s+wCSAAIAANNjGxgAAADkahbDMIzsDgK4V4mJiYqOjtbw4cPl5uaW3eEAyET8fAOOQwKIB9qVK1fk6+uruLg4+fj4ZHc4ADIRP9+A4zAFDAAAYDIkgAAAACZDAggAAGAyJIB4oLm5uSkqKooF4kAuxM834Dg8BAIAAGAyVAABAABMhgQQAADAZEgAAQAATIYEEAAAwGRIAPFAmzFjhkqWLCl3d3fVrl1bv/32W3aHBOA+/fzzz2rTpo0KFy4si8WiZcuWZXdIQK5DAogH1oIFCxQZGamoqCjt2LFDVatWVUREhM6ePZvdoQG4D9euXVPVqlU1Y8aM7A4FyLXYBgYPrNq1a6tmzZqaPn26JCklJUXFihXToEGD9Oqrr2ZzdAAyg8Vi0dKlS9WuXbvsDgXIVagA4oGUlJSk7du3Kzw83Nrm5OSk8PBwbdq0KRsjAwAg5yMBxAPp/PnzSk5OVkBAgE17QECAYmJisikqAAAeDCSAAAAAJkMCiAdSgQIF5OzsrNjYWJv22NhYBQYGZlNUAAA8GEgA8UBydXVVaGio1q1bZ21LSUnRunXrFBYWlo2RAQCQ8+XJ7gCAexUZGalevXqpRo0aqlWrlqZMmaJr166pT58+2R0agPsQHx+vI0eOWF8fP35cv//+u/Lly6fixYtnY2RA7sE2MHigTZ8+XZMmTVJMTIyqVaumadOmqXbt2tkdFoD78NNPP6lx48ap2nv16qW5c+dmfUBALkQCCAAAYDKsAQQAADAZEkAAAACTIQEEAAAwGRJAAAAAkyEBBAAAMBkSQAAAAJMhAQQAADAZEkAApnXp0iWNGTNGZ86cye5QACBLkQACSJPFYtGyZcuyOwyHMQxDvXr10o0bNxQUFHTHvqNHj1a1atWsr3v37q127do5NkAAcCASQMCEYmJiNGjQIJUuXVpubm4qVqyY2rRpo3Xr1mV3aFlm0qRJ8vHxUXR0tN3vnTp1qs2vJHvkkUc0ZMiQzAsOABwsT3YHACBrnThxQvXq1ZOfn58mTZqkypUr6+bNm1qzZo0GDBigAwcOZHeIDpGUlCRXV1fr65dffvmex/L19c2MkAAg21ABBEzm+eefl8Vi0W+//aaOHTuqXLlyqlSpkiIjI7V58+Z03/fKK6+oXLlyyps3r0qXLq1Ro0bp5s2b1vO7du1S48aN5e3tLR8fH4WGhmrbtm2SpJMnT6pNmzby9/eXp6enKlWqpJUrV1rfu2fPHrVo0UJeXl4KCAjQk08+qfPnz6cby9y5c+Xn56dly5YpODhY7u7uioiI0J9//mntc3va9sMPP1SpUqXk7u4uSbp8+bKefvppFSxYUD4+PmrSpIl27dplM/748eMVEBAgb29v9e3bVwkJCTbn/z0F3Lt3b61fv15Tp06VxWKRxWLRiRMn7um+ACCrkAACJnLx4kWtXr1aAwYMkKenZ6rzfn5+6b7X29tbc+fO1b59+zR16lTNnj1bkydPtp7v0aOHihYtqq1bt2r79u169dVX5eLiIkkaMGCAEhMT9fPPP2v37t2aMGGCvLy8JP2TkDVp0kQPP/ywtm3bptWrVys2NladO3e+471cv35db775pj799FNt2LBBly9fVteuXW36HDlyRIsXL9aSJUv0+++/S5I6deqks2fPatWqVdq+fbuqV6+upk2b6uLFi5Kkr776SqNHj9a4ceO0bds2BQUFaebMmenGMXXqVIWFhalfv346c+aMzpw5o2LFit3zfQFAljAAmMaWLVsMScaSJUvu2leSsXTp0nTPT5o0yQgNDbW+9vb2NubOnZtm38qVKxujR49O89wbb7xhNGvWzKbtzz//NCQZBw8eTPM9c+bMMSQZmzdvtrbt37/fkGRs2bLFMAzDiIqKMlxcXIyzZ89a+/zyyy+Gj4+PkZCQYDNemTJljPfff98wDMMICwsznn/+eZvztWvXNqpWrWp93atXL+Oxxx6zvm7UqJExePDg+74vAMgqVAABEzEM457fu2DBAtWrV0+BgYHy8vLSyJEjderUKev5yMhIPf300woPD9f48eN19OhR67kXXnhBY8eOVb169RQVFaU//vjDem7Xrl368ccf5eXlZT1CQkIkyWaM/8qTJ49q1qxpfR0SEiI/Pz/t37/f2laiRAkVLFjQ5lrx8fHKnz+/zfWOHz9uvdb+/ftVu3Ztm2uFhYXZ+3Hd830BQFbgIRDARIKDg2WxWOx+0GPTpk3q0aOHxowZo4iICPn6+mr+/Pl6++23rX1Gjx6t7t2769tvv9WqVasUFRWl+fPnq3379nr66acVERGhb7/9VmvXrlV0dLTefvttDRo0SPHx8WrTpo0mTJiQ6rp3257lbv47zR0fH6+goCD99NNPqfreafr7XjjyvgDgflEBBEwkX758ioiI0IwZM3Tt2rVU5y9fvpzm+zZu3KgSJUpoxIgRqlGjhoKDg3Xy5MlU/cqVK6ehQ4dq7dq16tChg+bMmWM9V6xYMT377LNasmSJXnzxRc2ePVuSVL16de3du1clS5ZU2bJlbY601ineduvWLetDJpJ08OBBXb58WRUqVEj3PdWrV1dMTIzy5MmT6loFChSQJFWoUEFbtmyxed+dHo6RJFdXVyUnJ6e61r3cFwBkBRJAwGRmzJih5ORk1apVS4sXL9bhw4e1f/9+TZs2Ld2pzuDgYJ06dUrz58/X0aNHNW3aNC1dutR6/saNGxo4cKB++uknnTx5Uhs2bNDWrVutydiQIUO0Zs0aHT9+XDt27NCPP/5oPTdgwABdvHhR3bp109atW3X06FGtWbNGffr0SZVU/ZuLi4sGDRqkLVu2aPv27erdu7fq1KmjWrVqpfue8PBwhYWFqV27dlq7dq1OnDihjRs3asSIEdZkcvDgwfr44481Z84cHTp0SFFRUdq7d+8dP9OSJUtqy5YtOnHihM6fP6+UlJR7vi8AyAokgIDJlC5dWjt27FDjxo314osv6qGHHtKjjz6qdevWadasWWm+p23btho6dKgGDhyoatWqaePGjRo1apT1vLOzsy5cuKCePXuqXLly6ty5s1q0aKExY8ZIkpKTkzVgwABVqFBBzZs3V7ly5axP1hYuXFgbNmxQcnKymjVrpsqVK2vIkCHy8/OTk1P6f0XlzZtXr7zyirp376569erJy8tLCxYsuOO9WywWrVy5Ug0bNlSfPn1Urlw5de3aVSdPnlRAQIAkqUuXLho1apRefvllhYaG6uTJk3ruuefuOO6wYcPk7OysihUrqmDBgjp16tQ93xcAZAWLcT+rwgEgG8ydO1dDhgxJd8oaAHBn/DMUAADAZEgAAQAATIYpYAAAAJOhAggAAGAyJIAAAAAmQwIIAABgMiSAAAAAJkMCCAAAYDIkgAAAACZDAggAAGAyJIAAAAAmQwIIAABgMv8P4kI+IbJq1tEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_lgbm = confusion_matrix(y_test, y_pred_lgbm)\n",
    "print(\"Matrice de confusion :\\n\", cm_lgbm)\n",
    "\n",
    "row_sums_lgbm = cm_lgbm.sum(axis = 1)\n",
    "cm_percent_lgbm = (cm_lgbm.T / row_sums_lgbm).T * 100\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_percent_lgbm, annot = True, fmt = \".2f\", cmap = \"Blues\")\n",
    "plt.xlabel('Classe prédite')\n",
    "plt.ylabel('Classe réelle')\n",
    "plt.title('Matrice de confusion avec pourcentages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Buffer has wrong number of dimensions (expected 1, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_indices \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m      2\u001b[0m df_test \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[test_indices]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      4\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrav\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_test\n",
      "File \u001b[0;32m~/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/pandas/core/indexes/base.py:6611\u001b[0m, in \u001b[0;36mIndex.isin\u001b[0;34m(self, values, level)\u001b[0m\n\u001b[1;32m   6609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   6610\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_index_level(level)\n\u001b[0;32m-> 6611\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/pandas/core/algorithms.py:545\u001b[0m, in \u001b[0;36misin\u001b[0;34m(comps, values)\u001b[0m\n\u001b[1;32m    542\u001b[0m     comps_array \u001b[38;5;241m=\u001b[39m comps_array\u001b[38;5;241m.\u001b[39mastype(common, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    543\u001b[0m     f \u001b[38;5;241m=\u001b[39m htable\u001b[38;5;241m.\u001b[39mismember\n\u001b[0;32m--> 545\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomps_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_func_helper.pxi:2691\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.__pyx_fuse_9ismember\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Buffer has wrong number of dimensions (expected 1, got 2)"
     ]
    }
   ],
   "source": [
    "test_indices = df.index.isin(X_test_scaled)  \n",
    "df_test = df.loc[test_indices].copy()\n",
    "\n",
    "df_test['grav'] = y_test\n",
    "df_test['Pred'] = y_pred_lgbm\n",
    "\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place</th>\n",
       "      <th>catu</th>\n",
       "      <th>grav</th>\n",
       "      <th>sexe</th>\n",
       "      <th>trajet</th>\n",
       "      <th>secu1</th>\n",
       "      <th>locp</th>\n",
       "      <th>catr</th>\n",
       "      <th>circ</th>\n",
       "      <th>nbv</th>\n",
       "      <th>vosp</th>\n",
       "      <th>prof</th>\n",
       "      <th>plan</th>\n",
       "      <th>surf</th>\n",
       "      <th>infra</th>\n",
       "      <th>situ</th>\n",
       "      <th>vma</th>\n",
       "      <th>lum</th>\n",
       "      <th>com</th>\n",
       "      <th>agg</th>\n",
       "      <th>int</th>\n",
       "      <th>atm</th>\n",
       "      <th>col</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>senc</th>\n",
       "      <th>catv</th>\n",
       "      <th>obs</th>\n",
       "      <th>obsm</th>\n",
       "      <th>choc</th>\n",
       "      <th>manv</th>\n",
       "      <th>motor</th>\n",
       "      <th>age_group</th>\n",
       "      <th>h_group</th>\n",
       "      <th>weekday</th>\n",
       "      <th>pred_lgbm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>26198</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>44.56</td>\n",
       "      <td>4.73</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>26198</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>44.56</td>\n",
       "      <td>4.73</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>25204</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>46.93</td>\n",
       "      <td>6.35</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>25204</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>46.93</td>\n",
       "      <td>6.35</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>22360</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>48.49</td>\n",
       "      <td>-2.76</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136924</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>34114</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>43.64</td>\n",
       "      <td>3.57</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136925</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>34114</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>43.64</td>\n",
       "      <td>3.57</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136926</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>34114</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>43.64</td>\n",
       "      <td>3.57</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136927</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>34114</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>43.64</td>\n",
       "      <td>3.57</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136928</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>30290</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>44.26</td>\n",
       "      <td>4.59</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136929 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        place  catu  grav  sexe  trajet  secu1  locp  catr  circ  nbv  vosp  \\\n",
       "0           1     1     2     1       5      1    -1     4     2    2     0   \n",
       "1           1     1     1     1       5      1    -1     4     2    2     0   \n",
       "2           1     1     2     1       9      1     0     4     2    2     0   \n",
       "3           1     1     1     1       4      1     0     4     2    2     0   \n",
       "4           1     1     1     1       0      1    -1     3    -1    2     0   \n",
       "...       ...   ...   ...   ...     ...    ...   ...   ...   ...  ...   ...   \n",
       "136924      7     2     1     2       5      1     0     1     3    4     0   \n",
       "136925      8     2     1     2       5      1     0     1     3    4     0   \n",
       "136926      9     2     1     2       5      1     0     1     3    4     0   \n",
       "136927      2     2     2     2       5      1     0     1     3    4     0   \n",
       "136928      2     2     2     2       5      2     0     3     2    2     0   \n",
       "\n",
       "        prof  plan  surf  infra  situ  vma  lum    com  agg  int  atm  col  \\\n",
       "0          1     1     1      0     1   50    1  26198    2    3    1    3   \n",
       "1          1     1     1      0     1   50    1  26198    2    3    1    3   \n",
       "2          1     1     1      0     1   50    1  25204    2    3    1    3   \n",
       "3          1     1     1      0     1   50    1  25204    2    3    1    3   \n",
       "4          1     1     1      5     1   50    1  22360    2    6    1    2   \n",
       "...      ...   ...   ...    ...   ...  ...  ...    ...  ...  ...  ...  ...   \n",
       "136924     1     2     2      0     1  110    3  34114    1    1    2    2   \n",
       "136925     1     2     2      0     1  110    3  34114    1    1    2    2   \n",
       "136926     1     2     2      0     1  110    3  34114    1    1    2    2   \n",
       "136927     1     2     2      0     1  110    3  34114    1    1    2    2   \n",
       "136928     1     2     2      0     3   80    2  30290    1    1    2    6   \n",
       "\n",
       "         lat  long  senc  catv  obs  obsm  choc  manv  motor  age_group  \\\n",
       "0      44.56  4.73     1     3    0     2     1     9      1          2   \n",
       "1      44.56  4.73     1     6    0     2     2     1      1          7   \n",
       "2      46.93  6.35     2     6    0     2     8    15      1          4   \n",
       "3      46.93  6.35     2     5    0     2     1     1      1          6   \n",
       "4      48.49 -2.76     2     6    0     2     1     2      1          3   \n",
       "...      ...   ...   ...   ...  ...   ...   ...   ...    ...        ...   \n",
       "136924 43.64  3.57     1     6    0     0     4     1      1          1   \n",
       "136925 43.64  3.57     1     6    0     0     4     1      1          1   \n",
       "136926 43.64  3.57     1     6    0     0     4     1      1          1   \n",
       "136927 43.64  3.57     1     6    0     0     4     1      1          7   \n",
       "136928 44.26  4.59     2     6   17     0     2     1      1          3   \n",
       "\n",
       "        h_group  weekday  pred_lgbm  \n",
       "0             6        2          2  \n",
       "1             6        2          1  \n",
       "2             3        3          2  \n",
       "3             3        3          2  \n",
       "4             6        3          2  \n",
       "...         ...      ...        ...  \n",
       "136924        3        6          1  \n",
       "136925        3        6          1  \n",
       "136926        3        6          1  \n",
       "136927        3        6          1  \n",
       "136928        3        6          1  \n",
       "\n",
       "[136929 rows x 36 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df.iloc[:len(y_test)]  \n",
    "\n",
    "df_filtered['pred_lgbm'] = y_pred_lgbm\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place</th>\n",
       "      <th>catu</th>\n",
       "      <th>grav</th>\n",
       "      <th>sexe</th>\n",
       "      <th>trajet</th>\n",
       "      <th>secu1</th>\n",
       "      <th>locp</th>\n",
       "      <th>catr</th>\n",
       "      <th>circ</th>\n",
       "      <th>nbv</th>\n",
       "      <th>vosp</th>\n",
       "      <th>prof</th>\n",
       "      <th>plan</th>\n",
       "      <th>surf</th>\n",
       "      <th>infra</th>\n",
       "      <th>situ</th>\n",
       "      <th>vma</th>\n",
       "      <th>lum</th>\n",
       "      <th>com</th>\n",
       "      <th>agg</th>\n",
       "      <th>int</th>\n",
       "      <th>atm</th>\n",
       "      <th>col</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>senc</th>\n",
       "      <th>catv</th>\n",
       "      <th>obs</th>\n",
       "      <th>obsm</th>\n",
       "      <th>choc</th>\n",
       "      <th>manv</th>\n",
       "      <th>motor</th>\n",
       "      <th>age_group</th>\n",
       "      <th>h_group</th>\n",
       "      <th>weekday</th>\n",
       "      <th>pred_lgbm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>25204</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>46.93</td>\n",
       "      <td>6.35</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>22360</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>48.49</td>\n",
       "      <td>-2.76</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>22360</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>48.49</td>\n",
       "      <td>-2.76</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>16102</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>45.69</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>16102</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>45.69</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136920</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>86070</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>46.57</td>\n",
       "      <td>0.73</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136921</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>59088</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>50.65</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136922</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>34114</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>43.64</td>\n",
       "      <td>3.57</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136927</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>34114</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>43.64</td>\n",
       "      <td>3.57</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136928</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>30290</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>44.26</td>\n",
       "      <td>4.59</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66692 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        place  catu  grav  sexe  trajet  secu1  locp  catr  circ  nbv  vosp  \\\n",
       "3           1     1     1     1       4      1     0     4     2    2     0   \n",
       "4           1     1     1     1       0      1    -1     3    -1    2     0   \n",
       "5           1     1     2     2       9      1    -1     3    -1    2     0   \n",
       "6           1     1     1     2       0      1    -1     4     1    1     0   \n",
       "7          10     3     2     2       5      2     1     4     1    1     0   \n",
       "...       ...   ...   ...   ...     ...    ...   ...   ...   ...  ...   ...   \n",
       "136920      1     1     2     2       5      1     0     3     1    2     0   \n",
       "136921      1     1     2     1       0      1     0     7     2    2     0   \n",
       "136922      1     1     1     1       5      1     0     1     3    4     0   \n",
       "136927      2     2     2     2       5      1     0     1     3    4     0   \n",
       "136928      2     2     2     2       5      2     0     3     2    2     0   \n",
       "\n",
       "        prof  plan  surf  infra  situ  vma  lum    com  agg  int  atm  col  \\\n",
       "3          1     1     1      0     1   50    1  25204    2    3    1    3   \n",
       "4          1     1     1      5     1   50    1  22360    2    6    1    2   \n",
       "5          1     1     1      5     1   50    1  22360    2    6    1    2   \n",
       "6          2     1     1      0     1   30    1  16102    2    3    8    6   \n",
       "7          2     1     1      0     1   30    1  16102    2    3    8    6   \n",
       "...      ...   ...   ...    ...   ...  ...  ...    ...  ...  ...  ...  ...   \n",
       "136920     1     1     1      0     1   90    1  86070    1    3    1    3   \n",
       "136921     1     3     2      0     3   70    5  59088    1    1    1    6   \n",
       "136922     1     2     2      0     1  110    3  34114    1    1    2    2   \n",
       "136927     1     2     2      0     1  110    3  34114    1    1    2    2   \n",
       "136928     1     2     2      0     3   80    2  30290    1    1    2    6   \n",
       "\n",
       "         lat  long  senc  catv  obs  obsm  choc  manv  motor  age_group  \\\n",
       "3      46.93  6.35     2     5    0     2     1     1      1          6   \n",
       "4      48.49 -2.76     2     6    0     2     1     2      1          3   \n",
       "5      48.49 -2.76     1     6    0     2     4     2      1          4   \n",
       "6      45.69 -0.33     2     6    0     1     3    16      1          3   \n",
       "7      45.69 -0.33     2     6    0     1     3    16      1          6   \n",
       "...      ...   ...   ...   ...  ...   ...   ...   ...    ...        ...   \n",
       "136920 46.57  0.73     2     6    0     0     8    15      1          5   \n",
       "136921 50.65  2.88     3     6    6     0     1    14      1          3   \n",
       "136922 43.64  3.57     1     6    0     2     1     0      1          3   \n",
       "136927 43.64  3.57     1     6    0     0     4     1      1          7   \n",
       "136928 44.26  4.59     2     6   17     0     2     1      1          3   \n",
       "\n",
       "        h_group  weekday  pred_lgbm  \n",
       "3             3        3          2  \n",
       "4             6        3          2  \n",
       "5             6        3          1  \n",
       "6             6        3          2  \n",
       "7             6        3          1  \n",
       "...         ...      ...        ...  \n",
       "136920        4        5          1  \n",
       "136921        1        6          1  \n",
       "136922        3        6          2  \n",
       "136927        3        6          1  \n",
       "136928        3        6          1  \n",
       "\n",
       "[66692 rows x 36 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mismatch = df_filtered[df_filtered['grav'] != df_filtered['pred_lgbm']]\n",
    "df_mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lum\n",
       " 1    45942\n",
       " 5     9273\n",
       " 3     6263\n",
       " 2     4683\n",
       " 4      530\n",
       "-1        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mismatch.lum.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lum\n",
       " 1    93804\n",
       " 5    19091\n",
       " 3    13142\n",
       " 2     9812\n",
       " 4     1077\n",
       "-1        3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.lum.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_acc_route",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
