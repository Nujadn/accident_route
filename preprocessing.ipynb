{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.max_info_columns\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n",
    "import lazypredict\n",
    "from lazypredict.supervised import LazyClassifier\n",
    "\n",
    "import sklearn\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier,GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place</th>\n",
       "      <th>catu</th>\n",
       "      <th>grav</th>\n",
       "      <th>sexe</th>\n",
       "      <th>an_nais</th>\n",
       "      <th>trajet</th>\n",
       "      <th>secu1</th>\n",
       "      <th>secu2</th>\n",
       "      <th>secu3</th>\n",
       "      <th>locp</th>\n",
       "      <th>actp</th>\n",
       "      <th>etatp</th>\n",
       "      <th>catr</th>\n",
       "      <th>v1</th>\n",
       "      <th>circ</th>\n",
       "      <th>nbv</th>\n",
       "      <th>vosp</th>\n",
       "      <th>prof</th>\n",
       "      <th>plan</th>\n",
       "      <th>larrout</th>\n",
       "      <th>surf</th>\n",
       "      <th>infra</th>\n",
       "      <th>situ</th>\n",
       "      <th>vma</th>\n",
       "      <th>Accident_Id</th>\n",
       "      <th>jour</th>\n",
       "      <th>mois</th>\n",
       "      <th>an</th>\n",
       "      <th>lum</th>\n",
       "      <th>dep</th>\n",
       "      <th>com</th>\n",
       "      <th>agg</th>\n",
       "      <th>int</th>\n",
       "      <th>atm</th>\n",
       "      <th>col</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>senc</th>\n",
       "      <th>catv</th>\n",
       "      <th>obs</th>\n",
       "      <th>obsm</th>\n",
       "      <th>choc</th>\n",
       "      <th>manv</th>\n",
       "      <th>motor</th>\n",
       "      <th>an_acc</th>\n",
       "      <th>heure</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2008.00</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>202200000001.00</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>26198</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>44.56</td>\n",
       "      <td>4.73</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1948.00</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>202200000001.00</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>26198</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>44.56</td>\n",
       "      <td>4.73</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1988.00</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>202200000002.00</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>25204</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>46.93</td>\n",
       "      <td>6.35</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1970.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>202200000002.00</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>25204</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>46.93</td>\n",
       "      <td>6.35</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2002.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>202200000003.00</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>22360</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>48.49</td>\n",
       "      <td>-2.76</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   place  catu  grav  sexe  an_nais  trajet  secu1  secu2  secu3  locp  actp  \\\n",
       "0      1     1     3     1  2008.00       5      2      8     -1    -1    -1   \n",
       "1      1     1     1     1  1948.00       5      1      8     -1    -1    -1   \n",
       "2      1     1     4     1  1988.00       9      1      0     -1     0     0   \n",
       "3      1     1     1     1  1970.00       4      1      0     -1     0     0   \n",
       "4      1     1     1     1  2002.00       0      1      0     -1    -1    -1   \n",
       "\n",
       "   etatp  catr   v1  circ  nbv  vosp  prof  plan  larrout  surf  infra  situ  \\\n",
       "0     -1     4 0.00     2    2     0     1     1    -1.00     1      0     1   \n",
       "1     -1     4 0.00     2    2     0     1     1    -1.00     1      0     1   \n",
       "2     -1     4 0.00     2    2     0     1     1    -1.00     1      0     1   \n",
       "3     -1     4 0.00     2    2     0     1     1    -1.00     1      0     1   \n",
       "4     -1     3 0.00    -1    2     0     1     1    -1.00     1      5     1   \n",
       "\n",
       "   vma     Accident_Id  jour  mois    an  lum  dep    com  agg  int  atm  col  \\\n",
       "0   50 202200000001.00    19    10  2022    1   26  26198    2    3    1    3   \n",
       "1   50 202200000001.00    19    10  2022    1   26  26198    2    3    1    3   \n",
       "2   50 202200000002.00    20    10  2022    1   25  25204    2    3    1    3   \n",
       "3   50 202200000002.00    20    10  2022    1   25  25204    2    3    1    3   \n",
       "4   50 202200000003.00    20    10  2022    1   22  22360    2    6    1    2   \n",
       "\n",
       "    lat  long  senc  catv  obs  obsm  choc  manv  motor  an_acc  heure  minute  \n",
       "0 44.56  4.73     1     2    0     2     1     9      1    2022     16      15  \n",
       "1 44.56  4.73     1     7    0     2     2     1      1    2022     16      15  \n",
       "2 46.93  6.35     2     7    0     2     8    15      1    2022      8      34  \n",
       "3 46.93  6.35     2    10    0     2     1     1      1    2022      8      34  \n",
       "4 48.49 -2.76     2     7    0     2     1     2      1    2022     17      15  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset_final.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr√©processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le nombre d'accident selon la place occup√© dans le transports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable \"-1\" correspond √† \"non concern√©\" et sont constitu√©s de 25 lignes. Elles sont donc supprim√©s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['place'] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trajet : transformer les non concern√© et non renseign√©\n",
    "df['trajet'] = df['trajet'].mask(df['trajet'] < 0, 0)\n",
    "\n",
    "\n",
    "# locp : regroupement de cat√©gorie entre elles\n",
    "df['locp'] = df['locp'].replace([2, 4], # 1 et 2 => 1 pour pi√©ton sur chauss√©\n",
    "                                [1, 2]) # 3 et 4 => 2 pour pi√©ton sur passage pi√©ton\n",
    "\n",
    "df['locp'] = df['locp'].replace([5,6,7,8,9], 3) # 5 √† 9 => 3 pour pi√©ton sur divers\n",
    "                                  \n",
    "df['nbv'] = df['nbv'].replace([9,10,11,12,13], 9) # 9 √† 13 => 9 pour plus de 9 noies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sexe\n",
       " 1    333870\n",
       " 2    154504\n",
       "-1      5783\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sexe.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grav\n",
      "1    207630\n",
      "4    197494\n",
      "3     75986\n",
      "2     13047\n",
      "Name: count, dtype: int64\n",
      "-1 : non concern√©, 1 ‚Äì Indemne, 2 ‚Äì Tu√©, 3 ‚Äì Bless√© hospitalis√©, 4 ‚Äì Bless√© l√©ger\n"
     ]
    }
   ],
   "source": [
    "print(df.grav.value_counts())\n",
    "\n",
    "print(\"-1 : non concern√©, 1 ‚Äì Indemne, 2 ‚Äì Tu√©, 3 ‚Äì Bless√© hospitalis√©, 4 ‚Äì Bless√© l√©ger\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on a pu le voir pr√©c√©demment, le jeu de donn√©es est d√©s√©quilibr√© sur la variable cible. Par exemple, la proportion d'accident mortel est plus faible que celle d'indemne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinaison de indemne et non concern√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grav\n",
      "2    286527\n",
      "1    207630\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Variables d'origines : 1 ‚Äì Indemne, 2 ‚Äì Tu√©, 3 ‚Äì Bless√© hospitalis√©, 4 ‚Äì Bless√© l√©ger\n",
      "Nouvelles variables  : 1 ‚Äì Accident sans gravit√©, 2 ‚Äì Accident avec gravit√©\n"
     ]
    }
   ],
   "source": [
    "# combiner les variables indemne et non concern√© car si la personne \n",
    "# n'est pas concern√© par la gravit√© c'est qu'elle est indemne\n",
    "\n",
    "df.grav = df.grav.astype(str)\n",
    "df.grav = [value.replace(\"-1\", \"1\") for value in df[\"grav\"]]\n",
    "df.grav = [value.replace(\"3\", \"2\") for value in df[\"grav\"]]\n",
    "df.grav = [value.replace(\"4\", \"2\") for value in df[\"grav\"]]\n",
    "df.grav = df.grav.astype(int)\n",
    "\n",
    "print(df.grav.value_counts())\n",
    "\n",
    "print(\"\")\n",
    "print(\"Variables d'origines :\", \"1 ‚Äì Indemne, 2 ‚Äì Tu√©, 3 ‚Äì Bless√© hospitalis√©, 4 ‚Äì Bless√© l√©ger\")\n",
    "print(\"Nouvelles variables  :\", \"1 ‚Äì Accident sans gravit√©, 2 ‚Äì Accident avec gravit√©\")\n",
    "\n",
    "# Pour la suite, je souhaite conserver pour la variable gravit√© les cat√©gories indemne, tu√©, bless√© hospitalis√© \n",
    "# et bless√© l√©ger qui me paraissent int√©ressantes pour traiter le probl√®me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S√©paration du jeu de donn√©es en train set et test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S√©paration des labels et targets : (347733, 39) (115912, 39) (347733,) (115912,)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['Accident_Id', \n",
    "                      \"an_acc\",\n",
    "                      \"larrout\",   # oublon avec la variable \"an\"\n",
    "                      \"secu3\",    # bcp de non concern√©s\n",
    "                      \"secu2\",    # bcp de non concern√©s\n",
    "                      \"actp\",     # bcp de non concern√©s \n",
    "                      \"etatp\"],   # bcp de non concern√©s \n",
    "                     axis=1)\n",
    "\n",
    "# Supression des lignes contenant des donn√©es manquantes\n",
    "df = df.dropna()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop([\"grav\"], axis=1), df.grav, test_size=0.25)\n",
    "print(\"S√©paration des labels et targets :\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = df.drop(['Accident_Id', \n",
    "                      \"an_acc\"], # doublon avec la variable \"an\"\n",
    "                     axis=1)\n",
    "\n",
    "# Supression des lignes contenant des donn√©es manquantes\n",
    "df = df.dropna()\n",
    "\n",
    "# S√©paration du jeu de donn√©es pour entra√Æner le mod√®le\n",
    "#train = df.loc[df.an.between(2019, 2021)] \n",
    "df_bis = df.loc[df.an.between(2020, 2022)]\n",
    "\n",
    "train = df_bis.loc[df_bis.an.between(2020, 2021)]\n",
    "test = df_bis.loc[df_bis.an == 2022]\n",
    "\n",
    "print(\"DF: \", df_bis.shape,\"TRAIN :\", train.shape,\"TEST :\", test.shape)\n",
    "print(\" \")\n",
    "print(\"La proportion du dataset train est de\", round((train.shape[0]/ df_bis.shape[0]*100)),\n",
    "      \"% et du dataset test est de\", round((test.shape[0]/ df_bis.shape[0]*100)), \"%.\")\n",
    "print(\" \")\n",
    "X_train = train.drop([\"grav\"], axis=1)\n",
    "y_train = train.grav\n",
    "\n",
    "X_test = test.drop([\"grav\"], axis=1)\n",
    "y_test = test.grav\n",
    "\n",
    "print(\"S√©paration des labels et targets :\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled_std = scaler.fit_transform(X_train)\n",
    "X_test_scaled_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "rbs = RobustScaler().fit(X_train)\n",
    "X_train_scaled_rbs = rbs.transform(X_train)\n",
    "X_test_scaled_rbs = rbs.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R√©-√©quilibrage de la variable cible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampler avec std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled_std, y_train_resampled = undersampler.fit_resample(X_train_scaled_std, y_train)\n",
    "\n",
    "model_baseline_res = LogisticRegression(random_state=0, solver='lbfgs', max_iter=1000)\n",
    "\n",
    "model_baseline_res.fit(X_train_resampled_std, y_train_resampled)\n",
    "accuracy_res = model_baseline_res.score(X_test_scaled_std, y_test)\n",
    "print(\"Accuracy :\", round(accuracy_res,6))\n",
    "\n",
    "y_pred = model_baseline_res.predict(X_test_scaled_std)\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred, colnames=['Predictions']))\n",
    "\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampler avec robustscaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled_rbs, y_train_resampled = undersampler.fit_resample(X_train_scaled_rbs, y_train)\n",
    "\n",
    "model_baseline_res = LogisticRegression(random_state=0, solver='lbfgs', max_iter=1000)\n",
    "\n",
    "model_baseline_res.fit(X_train_resampled_rbs, y_train_resampled)\n",
    "accuracy_res = model_baseline_res.score(X_test_scaled_rbs, y_test)\n",
    "print(\"Accuracy :\", round(accuracy_res,6))\n",
    "\n",
    "y_pred = model_baseline_res.predict(X_test_scaled_rbs)\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred, colnames=['Predictions']))\n",
    "\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampler avec std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_resampov_std, y_train_resampov = oversampler.fit_resample(X_train_scaled_std, y_train)\n",
    "\n",
    "model_baseline_res = LogisticRegression(random_state=0, solver='lbfgs', max_iter=1000)\n",
    "\n",
    "model_baseline_res.fit(X_train_resampov_std, y_train_resampov)\n",
    "accuracy_res = model_baseline_res.score(X_test_scaled_std, y_test)\n",
    "print(\"Accuracy :\", round(accuracy_res,6))\n",
    "\n",
    "y_pred = model_baseline_res.predict(X_test_scaled_std)\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred, colnames=['Predictions']))\n",
    "\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampler avec rbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_resampov_rbs, y_train_resampov = oversampler.fit_resample(X_train_scaled_rbs, y_train)\n",
    "\n",
    "model_baseline_res = LogisticRegression(random_state=0, solver='lbfgs', max_iter=1000)\n",
    "\n",
    "model_baseline_res.fit(X_train_resampov_rbs, y_train_resampov)\n",
    "accuracy_res = model_baseline_res.score(X_test_scaled_rbs, y_test)\n",
    "print(\"Accuracy :\", round(accuracy_res,6))\n",
    "\n",
    "y_pred = model_baseline_res.predict(X_test_scaled_rbs)\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred, colnames=['Predictions']))\n",
    "\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features select\n",
    "\n",
    "###### Faire la standardisation avant de s√©lectionner les variables est moins co√ªteux en terme de temps de calculs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recherche de la meilleure s√©lection de variables avec undersampling\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "best_accuracy = 0\n",
    "best_k = 0\n",
    "\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    select_k_best = SelectKBest(score_func=f_classif, k=k)\n",
    "    \n",
    "    X_train_k_best = select_k_best.fit_transform(X_train, y_train)\n",
    "    X_test_k_best = select_k_best.transform(X_test)\n",
    "    \n",
    "    model_2 = OneVsRestClassifier(LogisticRegression(random_state=0, solver='lbfgs', max_iter=1000))\n",
    "    model_2.fit(X_train_k_best, y_train)\n",
    "    \n",
    "    y_pred = model_2.predict(X_test_k_best)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_k = k\n",
    "\n",
    "print(\"Best number of features:\", best_k)\n",
    "print(\"Best accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recherche de la meilleure s√©lection de variables avec oversampling\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "best_accuracy = 0\n",
    "best_k = 0\n",
    "\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    select_k_best = SelectKBest(score_func=f_classif, k=k)\n",
    "    \n",
    "    X_train_k_best = select_k_best.fit_transform(X_train_resampov_, y_train_resampov)\n",
    "    X_test_k_best = select_k_best.transform(X_test_scaled_rbs)\n",
    "    \n",
    "    model_2 = OneVsRestClassifier(LogisticRegression(random_state=0, solver='lbfgs', max_iter=1000))\n",
    "    model_2.fit(X_train_k_best, y_train_resampov)\n",
    "    \n",
    "    y_pred = model_2.predict(X_test_k_best)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_k = k\n",
    "\n",
    "print(\"Best number of features:\", best_k)\n",
    "print(\"Best accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# s√©lection des k des meilleures features d√©finies pr√©c√©demment\n",
    "test_stat =  SelectKBest(f_classif, k=33)\n",
    "test_stat.fit(X_train_scaled, y_train)\n",
    "\n",
    "for col, score in zip(X_train.columns, test_stat.scores_):\n",
    "    print(col, \":\", score)\n",
    "\n",
    "X_train_selected = test_stat.transform(X_train_scaled)\n",
    "X_test_selected = test_stat.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R√©gression logistique : recherche de la meilleure \"normalisation\" des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler: Accuracy moyenne = 0.5920519420436421, √âcart-type = 0.0012786740888283547\n",
      "StandardScaler Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.77      0.68     48151\n",
      "           2       0.42      0.00      0.01      2834\n",
      "           3       0.46      0.19      0.27     17228\n",
      "           4       0.58      0.59      0.59     47699\n",
      "\n",
      "    accuracy                           0.59    115912\n",
      "   macro avg       0.52      0.39      0.39    115912\n",
      "weighted avg       0.57      0.59      0.56    115912\n",
      "\n",
      "MinMaxScaler: Accuracy moyenne = 0.5920979551268069, √âcart-type = 0.0011513296019927224\n",
      "MinMaxScaler Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.77      0.68     48151\n",
      "           2       0.33      0.00      0.00      2834\n",
      "           3       0.46      0.19      0.27     17228\n",
      "           4       0.58      0.59      0.59     47699\n",
      "\n",
      "    accuracy                           0.59    115912\n",
      "   macro avg       0.50      0.39      0.39    115912\n",
      "weighted avg       0.57      0.59      0.56    115912\n",
      "\n",
      "RobustScaler: Accuracy moyenne = 0.5921123337268446, √âcart-type = 0.0012128070309716703\n",
      "RobustScaler Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.77      0.68     48151\n",
      "           2       0.36      0.00      0.01      2834\n",
      "           3       0.46      0.19      0.27     17228\n",
      "           4       0.58      0.59      0.59     47699\n",
      "\n",
      "    accuracy                           0.59    115912\n",
      "   macro avg       0.50      0.39      0.39    115912\n",
      "weighted avg       0.57      0.59      0.56    115912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler()\n",
    "}\n",
    "\n",
    "model = LogisticRegression(random_state=0, solver='lbfgs', max_iter=1000)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    pipeline = make_pipeline(scaler, model)\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "    print(f\"{scaler_name}: Accuracy moyenne = {scores.mean()}, √âcart-type = {scores.std()}\")\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"{scaler_name} Classification Report:\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_baseline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[0;32m----> 3\u001b[0m y_pred_log \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_baseline\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_test_selected)\n\u001b[1;32m      5\u001b[0m conf_matrix_log \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_pred_log)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatrice de confusion :\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, conf_matrix_log)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_baseline' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred_log = model_baseline.predict(X_test_selected)\n",
    "\n",
    "conf_matrix_log = confusion_matrix(y_test, y_pred_log)\n",
    "print(\"Matrice de confusion :\\n\", conf_matrix_log)\n",
    "\n",
    "row_sums_log = conf_matrix_log.sum(axis=1)\n",
    "conf_matrix_percent_log = (conf_matrix_log.T / row_sums_log).T * 100\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix_percent_log, annot=True, fmt=\".2f\", cmap=\"Blues\")\n",
    "plt.xlabel('Classe pr√©dite')\n",
    "plt.ylabel('Classe r√©elle')\n",
    "plt.title('Matrice de confusion avec pourcentages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest : recherche de la meilleure \"normalisation\" des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler: Accuracy moyenne = 0.6836480886355647, √âcart-type = 0.002237072983282108\n",
      "MinMaxScaler: Accuracy moyenne = 0.6841743512852378, √âcart-type = 0.0019054375241854794\n",
      "RobustScaler: Accuracy moyenne = 0.6847408803498939, √âcart-type = 0.0017425095708648525\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(random_state=0, class_weight='balanced')\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    pipeline = make_pipeline(scaler, model_rf)\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "    print(f\"{scaler_name}: Accuracy moyenne = {scores.mean()}, √âcart-type = {scores.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN : recherche de la meilleure \"normalisation\" des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler: Accuracy moyenne = 0.45268491790183385, √âcart-type = 0.002397667752622828\n",
      "MinMaxScaler: Accuracy moyenne = 0.4256641721000968, √âcart-type = 0.006467772030212853\n",
      "RobustScaler: Accuracy moyenne = 0.4761988469142128, √âcart-type = 0.0044322465651383085\n"
     ]
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier()\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    pipeline = make_pipeline(scaler, model_knn)\n",
    "    \n",
    "    undersampler = RandomUnderSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    scores = cross_val_score(pipeline, X_train_resampled, y_train_resampled, cv=cv, scoring='accuracy')\n",
    "    \n",
    "    print(f\"{scaler_name}: Accuracy moyenne = {scores.mean()}, √âcart-type = {scores.std()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost : recherche de la meilleure \"normalisation\" des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler: Accuracy moyenne = 0.5778431280923595, √âcart-type = 0.004693858083687763\n",
      "MinMaxScaler: Accuracy moyenne = 0.5788491849679156, √âcart-type = 0.004196471115224787\n",
      "RobustScaler: Accuracy moyenne = 0.5779293638997789, √âcart-type = 0.004602568547734059\n"
     ]
    }
   ],
   "source": [
    "model_xgb = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    pipeline = make_pipeline(scaler, model_xgb)\n",
    "    \n",
    "    undersampler = RandomUnderSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    scores = cross_val_score(pipeline, X_train_resampled, y_train_resampled, cv=cv, scoring='accuracy')\n",
    "    \n",
    "    print(f\"{scaler_name}: Accuracy moyenne = {scores.mean()}, √âcart-type = {scores.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [ DummyClassifier ,  LogisticRegression ,  RandomForestClassifier ,  BaggingClassifier ,  AdaBoostClassifier ,\n",
    "                DecisionTreeClassifier ,  ExtraTreesClassifier ,\n",
    "                KNeighborsClassifier ,  XGBClassifier ,  LGBMClassifier,  GradientBoostingClassifier  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 9/11 [06:26<01:46, 53.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203295, number of negative: 144438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1432\n",
      "[LightGBM] [Info] Number of data points in the train set: 347733, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.584630 -> initscore=0.341808\n",
      "[LightGBM] [Info] Start training from score 0.341808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [08:00<00:00, 43.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'tuple' object has no attribute '__name__'\n",
      "Invalid Classifier(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 9/11 [04:23<00:57, 28.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203295, number of negative: 144438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1432\n",
      "[LightGBM] [Info] Number of data points in the train set: 347733, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.584630 -> initscore=0.341808\n",
      "[LightGBM] [Info] Start training from score 0.341808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [05:59<00:00, 32.72s/it]\n"
     ]
    }
   ],
   "source": [
    "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None,\n",
    "                     predictions = True, classifiers=models_list)\n",
    "\n",
    "models_train, predictions_train = clf.fit( X_train, X_train, y_train, y_train )\n",
    "\n",
    "# predict √† se renseigner !!\n",
    "models_test, predictions_test = clf.fit( X_train, X_test, y_train, y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performances des mod√®les sur l'ensemble d'entra√Ænement\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>69.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>83.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>42.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>159.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>3.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>90.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>21.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                        \n",
       "DecisionTreeClassifier          1.00               1.00     1.00      1.00   \n",
       "ExtraTreesClassifier            1.00               1.00     1.00      1.00   \n",
       "RandomForestClassifier          1.00               1.00     1.00      1.00   \n",
       "BaggingClassifier               0.99               0.99     0.99      0.99   \n",
       "KNeighborsClassifier            0.81               0.81     0.81      0.81   \n",
       "LGBMClassifier                  0.81               0.80     0.80      0.81   \n",
       "GradientBoostingClassifier      0.79               0.79     0.79      0.79   \n",
       "AdaBoostClassifier              0.78               0.78     0.78      0.78   \n",
       "LogisticRegression              0.72               0.71     0.71      0.72   \n",
       "DummyClassifier                 0.58               0.50     0.50      0.43   \n",
       "\n",
       "                            Time Taken  \n",
       "Model                                   \n",
       "DecisionTreeClassifier            6.87  \n",
       "ExtraTreesClassifier             69.91  \n",
       "RandomForestClassifier           83.29  \n",
       "BaggingClassifier                42.54  \n",
       "KNeighborsClassifier            159.91  \n",
       "LGBMClassifier                    3.43  \n",
       "GradientBoostingClassifier       90.84  \n",
       "AdaBoostClassifier               21.16  \n",
       "LogisticRegression                1.37  \n",
       "DummyClassifier                   0.70  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Performances des mod√®les sur l'ensemble d'entra√Ænement\\n\")\n",
    "models_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performances des mod√®les sur l'ensemble de test\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>61.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>2.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>93.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>40.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>19.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.74</td>\n",
       "      <td>6.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "      <td>54.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                        \n",
       "RandomForestClassifier          0.81               0.81     0.81      0.81   \n",
       "ExtraTreesClassifier            0.81               0.80     0.80      0.81   \n",
       "LGBMClassifier                  0.81               0.80     0.80      0.81   \n",
       "GradientBoostingClassifier      0.79               0.79     0.79      0.79   \n",
       "BaggingClassifier               0.79               0.79     0.79      0.79   \n",
       "AdaBoostClassifier              0.78               0.78     0.78      0.78   \n",
       "DecisionTreeClassifier          0.74               0.73     0.73      0.74   \n",
       "KNeighborsClassifier            0.71               0.71     0.71      0.72   \n",
       "LogisticRegression              0.72               0.71     0.71      0.72   \n",
       "DummyClassifier                 0.58               0.50     0.50      0.43   \n",
       "\n",
       "                            Time Taken  \n",
       "Model                                   \n",
       "RandomForestClassifier           79.99  \n",
       "ExtraTreesClassifier             61.72  \n",
       "LGBMClassifier                    2.72  \n",
       "GradientBoostingClassifier       93.46  \n",
       "BaggingClassifier                40.53  \n",
       "AdaBoostClassifier               19.08  \n",
       "DecisionTreeClassifier            6.47  \n",
       "KNeighborsClassifier             54.21  \n",
       "LogisticRegression                1.06  \n",
       "DummyClassifier                   0.46  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Performances des mod√®les sur l'ensemble de test\\n\")\n",
    "models_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde du df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset/df_go_modelisation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_acc_route",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
