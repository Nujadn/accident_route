{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.max_info_columns\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n",
    "import lazypredict\n",
    "from lazypredict.supervised import LazyClassifier\n",
    "\n",
    "import sklearn\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier,GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place</th>\n",
       "      <th>catu</th>\n",
       "      <th>grav</th>\n",
       "      <th>sexe</th>\n",
       "      <th>an_nais</th>\n",
       "      <th>trajet</th>\n",
       "      <th>secu1</th>\n",
       "      <th>secu2</th>\n",
       "      <th>secu3</th>\n",
       "      <th>locp</th>\n",
       "      <th>actp</th>\n",
       "      <th>etatp</th>\n",
       "      <th>catr</th>\n",
       "      <th>v1</th>\n",
       "      <th>circ</th>\n",
       "      <th>nbv</th>\n",
       "      <th>vosp</th>\n",
       "      <th>prof</th>\n",
       "      <th>plan</th>\n",
       "      <th>larrout</th>\n",
       "      <th>surf</th>\n",
       "      <th>infra</th>\n",
       "      <th>situ</th>\n",
       "      <th>vma</th>\n",
       "      <th>Accident_Id</th>\n",
       "      <th>jour</th>\n",
       "      <th>mois</th>\n",
       "      <th>an</th>\n",
       "      <th>lum</th>\n",
       "      <th>dep</th>\n",
       "      <th>com</th>\n",
       "      <th>agg</th>\n",
       "      <th>int</th>\n",
       "      <th>atm</th>\n",
       "      <th>col</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>senc</th>\n",
       "      <th>catv</th>\n",
       "      <th>obs</th>\n",
       "      <th>obsm</th>\n",
       "      <th>choc</th>\n",
       "      <th>manv</th>\n",
       "      <th>motor</th>\n",
       "      <th>an_acc</th>\n",
       "      <th>heure</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2008.00</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>202200000001.00</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>26198</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>44.56</td>\n",
       "      <td>4.73</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1948.00</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>202200000001.00</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>26198</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>44.56</td>\n",
       "      <td>4.73</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1988.00</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>202200000002.00</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>25204</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>46.93</td>\n",
       "      <td>6.35</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1970.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>202200000002.00</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>25204</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>46.93</td>\n",
       "      <td>6.35</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2002.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>202200000003.00</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>22360</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>48.49</td>\n",
       "      <td>-2.76</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   place  catu  grav  sexe  an_nais  trajet  secu1  secu2  secu3  locp  actp  \\\n",
       "0      1     1     3     1  2008.00       5      2      8     -1    -1    -1   \n",
       "1      1     1     1     1  1948.00       5      1      8     -1    -1    -1   \n",
       "2      1     1     4     1  1988.00       9      1      0     -1     0     0   \n",
       "3      1     1     1     1  1970.00       4      1      0     -1     0     0   \n",
       "4      1     1     1     1  2002.00       0      1      0     -1    -1    -1   \n",
       "\n",
       "   etatp  catr   v1  circ  nbv  vosp  prof  plan  larrout  surf  infra  situ  \\\n",
       "0     -1     4 0.00     2    2     0     1     1    -1.00     1      0     1   \n",
       "1     -1     4 0.00     2    2     0     1     1    -1.00     1      0     1   \n",
       "2     -1     4 0.00     2    2     0     1     1    -1.00     1      0     1   \n",
       "3     -1     4 0.00     2    2     0     1     1    -1.00     1      0     1   \n",
       "4     -1     3 0.00    -1    2     0     1     1    -1.00     1      5     1   \n",
       "\n",
       "   vma     Accident_Id  jour  mois    an  lum  dep    com  agg  int  atm  col  \\\n",
       "0   50 202200000001.00    19    10  2022    1   26  26198    2    3    1    3   \n",
       "1   50 202200000001.00    19    10  2022    1   26  26198    2    3    1    3   \n",
       "2   50 202200000002.00    20    10  2022    1   25  25204    2    3    1    3   \n",
       "3   50 202200000002.00    20    10  2022    1   25  25204    2    3    1    3   \n",
       "4   50 202200000003.00    20    10  2022    1   22  22360    2    6    1    2   \n",
       "\n",
       "    lat  long  senc  catv  obs  obsm  choc  manv  motor  an_acc  heure  minute  \n",
       "0 44.56  4.73     1     2    0     2     1     9      1    2022     16      15  \n",
       "1 44.56  4.73     1     7    0     2     2     1      1    2022     16      15  \n",
       "2 46.93  6.35     2     7    0     2     8    15      1    2022      8      34  \n",
       "3 46.93  6.35     2    10    0     2     1     1      1    2022      8      34  \n",
       "4 48.49 -2.76     2     7    0     2     1     2      1    2022     17      15  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset_final.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le nombre d'accident selon la place occupé dans le transports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable \"-1\" correspond à \"non concerné\" et sont constitués de 25 lignes. Elles sont donc supprimés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['place'] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trajet : transformer les non concerné et non renseigné\n",
    "df['trajet'] = df['trajet'].mask(df['trajet'] < 0, 0)\n",
    "\n",
    "\n",
    "# locp : regroupement de catégorie entre elles\n",
    "df['locp'] = df['locp'].replace([2, 4], # 1 et 2 => 1 pour piéton sur chaussé\n",
    "                                [1, 2]) # 3 et 4 => 2 pour piéton sur passage piéton\n",
    "\n",
    "df['locp'] = df['locp'].replace([5,6,7,8,9], 3) # 5 à 9 => 3 pour piéton sur divers\n",
    "                                  \n",
    "df['nbv'] = df['nbv'].replace([9,10,11,12,13], 9) # 9 à 13 => 9 pour plus de 9 noies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sexe\n",
       " 1    333870\n",
       " 2    154504\n",
       "-1      5783\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sexe.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grav\n",
      "1    207630\n",
      "4    197494\n",
      "3     75986\n",
      "2     13047\n",
      "Name: count, dtype: int64\n",
      "-1 : non concerné, 1 – Indemne, 2 – Tué, 3 – Blessé hospitalisé, 4 – Blessé léger\n"
     ]
    }
   ],
   "source": [
    "print(df.grav.value_counts())\n",
    "\n",
    "print(\"-1 : non concerné, 1 – Indemne, 2 – Tué, 3 – Blessé hospitalisé, 4 – Blessé léger\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on a pu le voir précédemment, le jeu de données est déséquilibré sur la variable cible. Par exemple, la proportion d'accident mortel est plus faible que celle d'indemne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinaison de indemne et non concerné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grav\n",
      "2    286527\n",
      "1    207630\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Variables d'origines : 1 – Indemne, 2 – Tué, 3 – Blessé hospitalisé, 4 – Blessé léger\n",
      "Nouvelles variables  : 1 – Accident sans gravité, 2 – Accident avec gravité\n"
     ]
    }
   ],
   "source": [
    "# combiner les variables indemne et non concerné car si la personne \n",
    "# n'est pas concerné par la gravité c'est qu'elle est indemne\n",
    "\n",
    "df.grav = df.grav.astype(str)\n",
    "df.grav = [value.replace(\"-1\", \"1\") for value in df[\"grav\"]]\n",
    "df.grav = [value.replace(\"3\", \"2\") for value in df[\"grav\"]]\n",
    "df.grav = [value.replace(\"4\", \"2\") for value in df[\"grav\"]]\n",
    "df.grav = df.grav.astype(int)\n",
    "\n",
    "print(df.grav.value_counts())\n",
    "\n",
    "print(\"\")\n",
    "print(\"Variables d'origines :\", \"1 – Indemne, 2 – Tué, 3 – Blessé hospitalisé, 4 – Blessé léger\")\n",
    "print(\"Nouvelles variables  :\", \"1 – Accident sans gravité, 2 – Accident avec gravité\")\n",
    "\n",
    "# Pour la suite, je souhaite conserver pour la variable gravité les catégories indemne, tué, blessé hospitalisé \n",
    "# et blessé léger qui me paraissent intéressantes pour traiter le problème."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation du jeu de données en train set et test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Séparation des labels et targets : (347733, 39) (115912, 39) (347733,) (115912,)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['Accident_Id', \n",
    "                      \"an_acc\",\n",
    "                      \"larrout\",   # oublon avec la variable \"an\"\n",
    "                      \"secu3\",    # bcp de non concernés\n",
    "                      \"secu2\",    # bcp de non concernés\n",
    "                      \"actp\",     # bcp de non concernés \n",
    "                      \"etatp\"],   # bcp de non concernés \n",
    "                     axis=1)\n",
    "\n",
    "# Supression des lignes contenant des données manquantes\n",
    "df = df.dropna()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop([\"grav\"], axis=1), df.grav, test_size=0.25)\n",
    "print(\"Séparation des labels et targets :\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = df.drop(['Accident_Id', \n",
    "                      \"an_acc\"], # doublon avec la variable \"an\"\n",
    "                     axis=1)\n",
    "\n",
    "# Supression des lignes contenant des données manquantes\n",
    "df = df.dropna()\n",
    "\n",
    "# Séparation du jeu de données pour entraîner le modèle\n",
    "#train = df.loc[df.an.between(2019, 2021)] \n",
    "df_bis = df.loc[df.an.between(2020, 2022)]\n",
    "\n",
    "train = df_bis.loc[df_bis.an.between(2020, 2021)]\n",
    "test = df_bis.loc[df_bis.an == 2022]\n",
    "\n",
    "print(\"DF: \", df_bis.shape,\"TRAIN :\", train.shape,\"TEST :\", test.shape)\n",
    "print(\" \")\n",
    "print(\"La proportion du dataset train est de\", round((train.shape[0]/ df_bis.shape[0]*100)),\n",
    "      \"% et du dataset test est de\", round((test.shape[0]/ df_bis.shape[0]*100)), \"%.\")\n",
    "print(\" \")\n",
    "X_train = train.drop([\"grav\"], axis=1)\n",
    "y_train = train.grav\n",
    "\n",
    "X_test = test.drop([\"grav\"], axis=1)\n",
    "y_test = test.grav\n",
    "\n",
    "print(\"Séparation des labels et targets :\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled_std = scaler.fit_transform(X_train)\n",
    "X_test_scaled_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "rbs = RobustScaler().fit(X_train)\n",
    "X_train_scaled_rbs = rbs.transform(X_train)\n",
    "X_test_scaled_rbs = rbs.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ré-équilibrage de la variable cible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampler avec std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled_std, y_train_resampled = undersampler.fit_resample(X_train_scaled_std, y_train)\n",
    "\n",
    "model_baseline_res = LogisticRegression(random_state=0, solver='lbfgs', max_iter=1000)\n",
    "\n",
    "model_baseline_res.fit(X_train_resampled_std, y_train_resampled)\n",
    "accuracy_res = model_baseline_res.score(X_test_scaled_std, y_test)\n",
    "print(\"Accuracy :\", round(accuracy_res,6))\n",
    "\n",
    "y_pred = model_baseline_res.predict(X_test_scaled_std)\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred, colnames=['Predictions']))\n",
    "\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampler avec robustscaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled_rbs, y_train_resampled = undersampler.fit_resample(X_train_scaled_rbs, y_train)\n",
    "\n",
    "model_baseline_res = LogisticRegression(random_state=0, solver='lbfgs', max_iter=1000)\n",
    "\n",
    "model_baseline_res.fit(X_train_resampled_rbs, y_train_resampled)\n",
    "accuracy_res = model_baseline_res.score(X_test_scaled_rbs, y_test)\n",
    "print(\"Accuracy :\", round(accuracy_res,6))\n",
    "\n",
    "y_pred = model_baseline_res.predict(X_test_scaled_rbs)\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred, colnames=['Predictions']))\n",
    "\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampler avec std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_resampov_std, y_train_resampov = oversampler.fit_resample(X_train_scaled_std, y_train)\n",
    "\n",
    "model_baseline_res = LogisticRegression(random_state=0, solver='lbfgs', max_iter=1000)\n",
    "\n",
    "model_baseline_res.fit(X_train_resampov_std, y_train_resampov)\n",
    "accuracy_res = model_baseline_res.score(X_test_scaled_std, y_test)\n",
    "print(\"Accuracy :\", round(accuracy_res,6))\n",
    "\n",
    "y_pred = model_baseline_res.predict(X_test_scaled_std)\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred, colnames=['Predictions']))\n",
    "\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampler avec rbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_resampov_rbs, y_train_resampov = oversampler.fit_resample(X_train_scaled_rbs, y_train)\n",
    "\n",
    "model_baseline_res = LogisticRegression(random_state=0, solver='lbfgs', max_iter=1000)\n",
    "\n",
    "model_baseline_res.fit(X_train_resampov_rbs, y_train_resampov)\n",
    "accuracy_res = model_baseline_res.score(X_test_scaled_rbs, y_test)\n",
    "print(\"Accuracy :\", round(accuracy_res,6))\n",
    "\n",
    "y_pred = model_baseline_res.predict(X_test_scaled_rbs)\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred, colnames=['Predictions']))\n",
    "\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features select\n",
    "\n",
    "###### Faire la standardisation avant de sélectionner les variables est moins coûteux en terme de temps de calculs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recherche de la meilleure sélection de variables avec undersampling\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "best_accuracy = 0\n",
    "best_k = 0\n",
    "\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    select_k_best = SelectKBest(score_func=f_classif, k=k)\n",
    "    \n",
    "    X_train_k_best = select_k_best.fit_transform(X_train, y_train)\n",
    "    X_test_k_best = select_k_best.transform(X_test)\n",
    "    \n",
    "    model_2 = OneVsRestClassifier(LogisticRegression(random_state=0, solver='lbfgs', max_iter=1000))\n",
    "    model_2.fit(X_train_k_best, y_train)\n",
    "    \n",
    "    y_pred = model_2.predict(X_test_k_best)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_k = k\n",
    "\n",
    "print(\"Best number of features:\", best_k)\n",
    "print(\"Best accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recherche de la meilleure sélection de variables avec oversampling\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "best_accuracy = 0\n",
    "best_k = 0\n",
    "\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    select_k_best = SelectKBest(score_func=f_classif, k=k)\n",
    "    \n",
    "    X_train_k_best = select_k_best.fit_transform(X_train_resampov_, y_train_resampov)\n",
    "    X_test_k_best = select_k_best.transform(X_test_scaled_rbs)\n",
    "    \n",
    "    model_2 = OneVsRestClassifier(LogisticRegression(random_state=0, solver='lbfgs', max_iter=1000))\n",
    "    model_2.fit(X_train_k_best, y_train_resampov)\n",
    "    \n",
    "    y_pred = model_2.predict(X_test_k_best)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_k = k\n",
    "\n",
    "print(\"Best number of features:\", best_k)\n",
    "print(\"Best accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sélection des k des meilleures features définies précédemment\n",
    "test_stat =  SelectKBest(f_classif, k=33)\n",
    "test_stat.fit(X_train_scaled, y_train)\n",
    "\n",
    "for col, score in zip(X_train.columns, test_stat.scores_):\n",
    "    print(col, \":\", score)\n",
    "\n",
    "X_train_selected = test_stat.transform(X_train_scaled)\n",
    "X_test_selected = test_stat.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Régression logistique : recherche de la meilleure \"normalisation\" des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler: Accuracy moyenne = 0.5920519420436421, Écart-type = 0.0012786740888283547\n",
      "StandardScaler Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.77      0.68     48151\n",
      "           2       0.42      0.00      0.01      2834\n",
      "           3       0.46      0.19      0.27     17228\n",
      "           4       0.58      0.59      0.59     47699\n",
      "\n",
      "    accuracy                           0.59    115912\n",
      "   macro avg       0.52      0.39      0.39    115912\n",
      "weighted avg       0.57      0.59      0.56    115912\n",
      "\n",
      "MinMaxScaler: Accuracy moyenne = 0.5920979551268069, Écart-type = 0.0011513296019927224\n",
      "MinMaxScaler Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.77      0.68     48151\n",
      "           2       0.33      0.00      0.00      2834\n",
      "           3       0.46      0.19      0.27     17228\n",
      "           4       0.58      0.59      0.59     47699\n",
      "\n",
      "    accuracy                           0.59    115912\n",
      "   macro avg       0.50      0.39      0.39    115912\n",
      "weighted avg       0.57      0.59      0.56    115912\n",
      "\n",
      "RobustScaler: Accuracy moyenne = 0.5921123337268446, Écart-type = 0.0012128070309716703\n",
      "RobustScaler Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.77      0.68     48151\n",
      "           2       0.36      0.00      0.01      2834\n",
      "           3       0.46      0.19      0.27     17228\n",
      "           4       0.58      0.59      0.59     47699\n",
      "\n",
      "    accuracy                           0.59    115912\n",
      "   macro avg       0.50      0.39      0.39    115912\n",
      "weighted avg       0.57      0.59      0.56    115912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler()\n",
    "}\n",
    "\n",
    "model = LogisticRegression(random_state=0, solver='lbfgs', max_iter=1000)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    pipeline = make_pipeline(scaler, model)\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "    print(f\"{scaler_name}: Accuracy moyenne = {scores.mean()}, Écart-type = {scores.std()}\")\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"{scaler_name} Classification Report:\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_baseline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[0;32m----> 3\u001b[0m y_pred_log \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_baseline\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_test_selected)\n\u001b[1;32m      5\u001b[0m conf_matrix_log \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_pred_log)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatrice de confusion :\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, conf_matrix_log)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_baseline' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred_log = model_baseline.predict(X_test_selected)\n",
    "\n",
    "conf_matrix_log = confusion_matrix(y_test, y_pred_log)\n",
    "print(\"Matrice de confusion :\\n\", conf_matrix_log)\n",
    "\n",
    "row_sums_log = conf_matrix_log.sum(axis=1)\n",
    "conf_matrix_percent_log = (conf_matrix_log.T / row_sums_log).T * 100\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix_percent_log, annot=True, fmt=\".2f\", cmap=\"Blues\")\n",
    "plt.xlabel('Classe prédite')\n",
    "plt.ylabel('Classe réelle')\n",
    "plt.title('Matrice de confusion avec pourcentages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest : recherche de la meilleure \"normalisation\" des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler: Accuracy moyenne = 0.6836480886355647, Écart-type = 0.002237072983282108\n",
      "MinMaxScaler: Accuracy moyenne = 0.6841743512852378, Écart-type = 0.0019054375241854794\n",
      "RobustScaler: Accuracy moyenne = 0.6847408803498939, Écart-type = 0.0017425095708648525\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(random_state=0, class_weight='balanced')\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    pipeline = make_pipeline(scaler, model_rf)\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "    print(f\"{scaler_name}: Accuracy moyenne = {scores.mean()}, Écart-type = {scores.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN : recherche de la meilleure \"normalisation\" des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler: Accuracy moyenne = 0.45268491790183385, Écart-type = 0.002397667752622828\n",
      "MinMaxScaler: Accuracy moyenne = 0.4256641721000968, Écart-type = 0.006467772030212853\n",
      "RobustScaler: Accuracy moyenne = 0.4761988469142128, Écart-type = 0.0044322465651383085\n"
     ]
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier()\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    pipeline = make_pipeline(scaler, model_knn)\n",
    "    \n",
    "    undersampler = RandomUnderSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    scores = cross_val_score(pipeline, X_train_resampled, y_train_resampled, cv=cv, scoring='accuracy')\n",
    "    \n",
    "    print(f\"{scaler_name}: Accuracy moyenne = {scores.mean()}, Écart-type = {scores.std()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost : recherche de la meilleure \"normalisation\" des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler: Accuracy moyenne = 0.5778431280923595, Écart-type = 0.004693858083687763\n",
      "MinMaxScaler: Accuracy moyenne = 0.5788491849679156, Écart-type = 0.004196471115224787\n",
      "RobustScaler: Accuracy moyenne = 0.5779293638997789, Écart-type = 0.004602568547734059\n"
     ]
    }
   ],
   "source": [
    "model_xgb = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    pipeline = make_pipeline(scaler, model_xgb)\n",
    "    \n",
    "    undersampler = RandomUnderSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    scores = cross_val_score(pipeline, X_train_resampled, y_train_resampled, cv=cv, scoring='accuracy')\n",
    "    \n",
    "    print(f\"{scaler_name}: Accuracy moyenne = {scores.mean()}, Écart-type = {scores.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [ DummyClassifier ,  LogisticRegression ,  RandomForestClassifier ,  BaggingClassifier ,  AdaBoostClassifier ,\n",
    "                DecisionTreeClassifier ,  ExtraTreesClassifier ,\n",
    "                KNeighborsClassifier ,  XGBClassifier ,  LGBMClassifier,  GradientBoostingClassifier  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 9/11 [06:26<01:46, 53.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203295, number of negative: 144438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1432\n",
      "[LightGBM] [Info] Number of data points in the train set: 347733, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.584630 -> initscore=0.341808\n",
      "[LightGBM] [Info] Start training from score 0.341808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [08:00<00:00, 43.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'tuple' object has no attribute '__name__'\n",
      "Invalid Classifier(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 9/11 [04:23<00:57, 28.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203295, number of negative: 144438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1432\n",
      "[LightGBM] [Info] Number of data points in the train set: 347733, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.584630 -> initscore=0.341808\n",
      "[LightGBM] [Info] Start training from score 0.341808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [05:59<00:00, 32.72s/it]\n"
     ]
    }
   ],
   "source": [
    "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None,\n",
    "                     predictions = True, classifiers=models_list)\n",
    "\n",
    "models_train, predictions_train = clf.fit( X_train, X_train, y_train, y_train )\n",
    "\n",
    "# predict à se renseigner !!\n",
    "models_test, predictions_test = clf.fit( X_train, X_test, y_train, y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performances des modèles sur l'ensemble d'entraînement\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>69.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>83.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>42.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>159.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>3.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>90.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>21.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                        \n",
       "DecisionTreeClassifier          1.00               1.00     1.00      1.00   \n",
       "ExtraTreesClassifier            1.00               1.00     1.00      1.00   \n",
       "RandomForestClassifier          1.00               1.00     1.00      1.00   \n",
       "BaggingClassifier               0.99               0.99     0.99      0.99   \n",
       "KNeighborsClassifier            0.81               0.81     0.81      0.81   \n",
       "LGBMClassifier                  0.81               0.80     0.80      0.81   \n",
       "GradientBoostingClassifier      0.79               0.79     0.79      0.79   \n",
       "AdaBoostClassifier              0.78               0.78     0.78      0.78   \n",
       "LogisticRegression              0.72               0.71     0.71      0.72   \n",
       "DummyClassifier                 0.58               0.50     0.50      0.43   \n",
       "\n",
       "                            Time Taken  \n",
       "Model                                   \n",
       "DecisionTreeClassifier            6.87  \n",
       "ExtraTreesClassifier             69.91  \n",
       "RandomForestClassifier           83.29  \n",
       "BaggingClassifier                42.54  \n",
       "KNeighborsClassifier            159.91  \n",
       "LGBMClassifier                    3.43  \n",
       "GradientBoostingClassifier       90.84  \n",
       "AdaBoostClassifier               21.16  \n",
       "LogisticRegression                1.37  \n",
       "DummyClassifier                   0.70  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Performances des modèles sur l'ensemble d'entraînement\\n\")\n",
    "models_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performances des modèles sur l'ensemble de test\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>61.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>2.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>93.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>40.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>19.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.74</td>\n",
       "      <td>6.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "      <td>54.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                        \n",
       "RandomForestClassifier          0.81               0.81     0.81      0.81   \n",
       "ExtraTreesClassifier            0.81               0.80     0.80      0.81   \n",
       "LGBMClassifier                  0.81               0.80     0.80      0.81   \n",
       "GradientBoostingClassifier      0.79               0.79     0.79      0.79   \n",
       "BaggingClassifier               0.79               0.79     0.79      0.79   \n",
       "AdaBoostClassifier              0.78               0.78     0.78      0.78   \n",
       "DecisionTreeClassifier          0.74               0.73     0.73      0.74   \n",
       "KNeighborsClassifier            0.71               0.71     0.71      0.72   \n",
       "LogisticRegression              0.72               0.71     0.71      0.72   \n",
       "DummyClassifier                 0.58               0.50     0.50      0.43   \n",
       "\n",
       "                            Time Taken  \n",
       "Model                                   \n",
       "RandomForestClassifier           79.99  \n",
       "ExtraTreesClassifier             61.72  \n",
       "LGBMClassifier                    2.72  \n",
       "GradientBoostingClassifier       93.46  \n",
       "BaggingClassifier                40.53  \n",
       "AdaBoostClassifier               19.08  \n",
       "DecisionTreeClassifier            6.47  \n",
       "KNeighborsClassifier             54.21  \n",
       "LogisticRegression                1.06  \n",
       "DummyClassifier                   0.46  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Performances des modèles sur l'ensemble de test\\n\")\n",
    "models_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde du df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset/df_go_modelisation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_acc_route",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
