{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place</th>\n",
       "      <th>catu</th>\n",
       "      <th>grav</th>\n",
       "      <th>sexe</th>\n",
       "      <th>an_nais</th>\n",
       "      <th>trajet</th>\n",
       "      <th>secu1</th>\n",
       "      <th>secu2</th>\n",
       "      <th>secu3</th>\n",
       "      <th>locp</th>\n",
       "      <th>...</th>\n",
       "      <th>long</th>\n",
       "      <th>senc</th>\n",
       "      <th>catv</th>\n",
       "      <th>obs</th>\n",
       "      <th>obsm</th>\n",
       "      <th>choc</th>\n",
       "      <th>manv</th>\n",
       "      <th>motor</th>\n",
       "      <th>heure</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.725720</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1948.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.725720</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.346200</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.346200</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.760439</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   place  catu  grav  sexe  an_nais  trajet  secu1  secu2  secu3  locp  ...  \\\n",
       "0      1     1     2     1   2008.0       5      2      8     -1    -1  ...   \n",
       "1      1     1     1     1   1948.0       5      1      8     -1    -1  ...   \n",
       "2      1     1     2     1   1988.0       9      1      0     -1     0  ...   \n",
       "3      1     1     1     1   1970.0       4      1      0     -1     0  ...   \n",
       "4      1     1     1     1   2002.0       0      1      0     -1    -1  ...   \n",
       "\n",
       "       long  senc  catv  obs  obsm  choc  manv  motor  heure  minute  \n",
       "0  4.725720     1     2    0     2     1     9      1     16      15  \n",
       "1  4.725720     1     7    0     2     2     1      1     16      15  \n",
       "2  6.346200     2     7    0     2     8    15      1      8      34  \n",
       "3  6.346200     2    10    0     2     1     1      1      8      34  \n",
       "4 -2.760439     2     7    0     2     1     2      1     17      15  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"df_go_modelisation.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Séparation des labels et targets : (347733, 43) (115912, 43) (347733,) (115912,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop([\"grav\"], axis=1), df.grav, test_size=0.25)\n",
    "print(\"Séparation des labels et targets :\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Choix des modèles\n",
    "\n",
    "Le choix s'est porté sur les modèles de logistic Regression, AdaBoost et Lgbm, puisqu'ils ne souffrent pas de sur-apprentissage ou de sous-apprentissage tout en offrant de bonnes performances.\n",
    "\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres trouvés: {'C': 0.01, 'solver': 'liblinear'}\n",
      "Meilleur score de validation croisée: 0.7093948491446384\n"
     ]
    }
   ],
   "source": [
    "hyper_p_lr = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  \n",
    "#    'penalty': ['l1', 'l2'],              \n",
    "    'solver': ['liblinear', 'saga']       \n",
    "}\n",
    "\n",
    "gs_lr = GridSearchCV(estimator = LogisticRegression(max_iter = 1000),\n",
    "                           param_grid = hyper_p_lr,\n",
    "                           cv = 5,  # Nombre de folds pour la validation croisée\n",
    "                           verbose = 1,\n",
    "                           n_jobs = -1)  # Utiliser tous les coeurs du CPU\n",
    "\n",
    "gs_lr.fit(X_train, y_train)\n",
    "\n",
    "best_hp_lr = gs_lr.best_params_\n",
    "best_score_lr = gs_lr.best_score_\n",
    "\n",
    "print(\"Meilleurs paramètres trouvés:\", best_hp_lr)\n",
    "print(\"Meilleur score de validation croisée:\", best_score_lr)\n",
    "\n",
    "best_model = gs_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = best_model.predict(X_test)\n",
    "\n",
    "cv_results = gs_lr.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrice de logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      " [[31051 17274]\n",
      " [16910 50677]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "print(\"Matrice de confusion :\\n\", cm_lr)\n",
    "\n",
    "row_sums_lr = cm_lr.sum(axis = 1)\n",
    "cm_percent_lr = (cm_lr.T / row_sums_lr).T * 100\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_percent_lr, annot = True, fmt = \".2f\", cmap = \"Blues\")\n",
    "plt.xlabel('Classe prédite')\n",
    "plt.ylabel('Classe réelle')\n",
    "plt.title('Matrice de confusion avec pourcentages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_ada = {\n",
    "    'n_estimators': [50, 100, 200],        # Nombre de classificateurs faibles\n",
    "    'learning_rate': [0.01, 0.1, 1.0],     # Taux d'apprentissage\n",
    "    'algorithm': ['SAMME', 'SAMME.R']      # Algorithme utilisé\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_ada= GridSearchCV(estimator=AdaBoostClassifier(),\n",
    "                           param_grid = hp_ada,\n",
    "                           cv=5,  # Nombre de folds pour la validation croisée\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)  # Utiliser tous les coeurs du CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/yu/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=AdaBoostClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;algorithm&#x27;: [&#x27;SAMME&#x27;, &#x27;SAMME.R&#x27;],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.1, 1.0],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 200]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=AdaBoostClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;algorithm&#x27;: [&#x27;SAMME&#x27;, &#x27;SAMME.R&#x27;],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.1, 1.0],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 200]},\n",
       "             verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: AdaBoostClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>AdaBoostClassifier(n_estimators=200)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;AdaBoostClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\">?<span>Documentation for AdaBoostClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>AdaBoostClassifier(n_estimators=200)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=AdaBoostClassifier(), n_jobs=-1,\n",
       "             param_grid={'algorithm': ['SAMME', 'SAMME.R'],\n",
       "                         'learning_rate': [0.01, 0.1, 1.0],\n",
       "                         'n_estimators': [50, 100, 200]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres trouvés: {'algorithm': 'SAMME.R', 'learning_rate': 1.0, 'n_estimators': 200}\n",
      "Meilleur score de validation croisée: 0.792984854109458\n"
     ]
    }
   ],
   "source": [
    "best_hp_ada = gs_ada.best_params_\n",
    "best_score_ada = gs_ada.best_score_\n",
    "best_estimator_ada = gs_ada.best_estimator_\n",
    "\n",
    "print(\"Meilleurs paramètres trouvés:\", best_hp_ada)\n",
    "print(\"Meilleur score de validation croisée:\", best_score_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ada = best_estimator_ada.predict(X_test)\n",
    "\n",
    "cv_results_ada = gs_ada.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrice de confusion de Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      " [[37550 10775]\n",
      " [13585 54002]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_ada = confusion_matrix(y_test, y_pred_ada)\n",
    "print(\"Matrice de confusion :\\n\", cm_ada)\n",
    "\n",
    "row_sums_ada = cm_ada.sum(axis = 1)\n",
    "cm_percent_ada = (cm_ada.T / row_sums_ada).T * 100\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_percent_ada, annot = True, fmt = \".2f\", cmap = \"Blues\")\n",
    "plt.xlabel('Classe prédite')\n",
    "plt.ylabel('Classe réelle')\n",
    "plt.title('Matrice de confusion avec pourcentages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_lgbm = {\n",
    "    'learning_rate': [0.01, 0.1, 1.0],                # Taux d'apprentissage\n",
    "    'n_estimators': [50, 100],                   # Nombre d'estimateurs\n",
    "    'num_leaves': [20, 30, 40],                        # Nombre maximum de feuilles par arbre\n",
    "    'boosting_type': ['gbdt', 'dart', 'goss'],        # Type de boosting\n",
    "    'subsample': [0.8, 1.0],                          # Sous-échantillonnage des données\n",
    "    'colsample_bytree': [0.8, 1.0]                    # Fraction de colonnes à utiliser par arbre\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_lgbm = GridSearchCV(estimator=LGBMClassifier(),\n",
    "                           param_grid= hp_lgbm,\n",
    "                           cv=5,  # Nombre de folds pour la validation croisée\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)  # Utiliser tous les coeurs du CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115388\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115388\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.947667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1466\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.065321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1470[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.699327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585213 -> initscore=0.344210\n",
      "\n",
      "[LightGBM] [Info] Start training from score 0.344210\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.997420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.309728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1470\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585213 -> initscore=0.344210\n",
      "[LightGBM] [Info] Start training from score 0.344210\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.979421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1468\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.143766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.079603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1466\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] Start training from score 0.344201[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.336601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1466\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.082553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1468\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.394614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.305230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115388\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.647049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1470\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585213 -> initscore=0.344210\n",
      "[LightGBM] [Info] Start training from score 0.344210\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.955445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1468\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.941624 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.078918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1466\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.858865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115388\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.867547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1470\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585213 -> initscore=0.344210\n",
      "[LightGBM] [Info] Start training from score 0.344210\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.825570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1468\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.070181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.217622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1466\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.015957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115388\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.121083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1470\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585213 -> initscore=0.344210\n",
      "[LightGBM] [Info] Start training from score 0.344210\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.967192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1468\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.464795 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.656328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1466\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.666440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115388\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.412660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1468\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.604327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1470\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585213 -> initscore=0.344210\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344210\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.748517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.376268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1466\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.813146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115388\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.514063 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1470\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585213 -> initscore=0.344210\n",
      "[LightGBM] [Info] Start training from score 0.344210\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.603674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1468\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.664781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.483861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1466\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.312026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115388\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.643839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1470\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585213 -> initscore=0.344210\n",
      "[LightGBM] [Info] Start training from score 0.344210\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.629014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1468\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.489399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.573770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1466\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.479168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115388\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.558571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1470\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585213 -> initscore=0.344210\n",
      "[LightGBM] [Info] Start training from score 0.344210\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.388553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1468\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.546815 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.930138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1466\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.673840 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115388\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.641651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1470\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585213 -> initscore=0.344210\n",
      "[LightGBM] [Info] Start training from score 0.344210\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.501269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1468\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.585136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.430709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1466\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.607075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115388\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.516395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1470\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585213 -> initscore=0.344210\n",
      "[LightGBM] [Info] Start training from score 0.344210\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.082837 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1468\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.768675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.678549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1466\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.527616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115388\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.347411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1470\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585213 -> initscore=0.344210\n",
      "[LightGBM] [Info] Start training from score 0.344210\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.470940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1468\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.623481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.518926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1466\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.482133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115388\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.619522 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1470\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585213 -> initscore=0.344210\n",
      "[LightGBM] [Info] Start training from score 0.344210\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.706005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1468\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.603718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.517814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1466\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.568106 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115388\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.560322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1470\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585213 -> initscore=0.344210\n",
      "[LightGBM] [Info] Start training from score 0.344210\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.531656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1468\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.604419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.518879 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1466\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.643663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115388\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.693502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1470\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585213 -> initscore=0.344210\n",
      "[LightGBM] [Info] Start training from score 0.344210\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.937023 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1468\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.454912 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.823352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1466\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.521087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115388\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.659327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1470\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585213 -> initscore=0.344210\n",
      "[LightGBM] [Info] Start training from score 0.344210\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.173195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1468\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Number of positive: 162798, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.058752 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278187, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585211 -> initscore=0.344201\n",
      "[LightGBM] [Info] Start training from score 0.344201\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.998575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1466\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n",
      "[LightGBM] [Info] Number of positive: 162797, number of negative: 115389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.090588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 278186, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.585209 -> initscore=0.344195\n",
      "[LightGBM] [Info] Start training from score 0.344195\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgs_lgbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/model_selection/_search.py:968\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    962\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    963\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    964\u001b[0m     )\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 968\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    972\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1543\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1542\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1543\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/model_selection/_search.py:914\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    910\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    911\u001b[0m         )\n\u001b[1;32m    912\u001b[0m     )\n\u001b[0;32m--> 914\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    934\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    935\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m     )\n",
      "File \u001b[0;32m~/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/acc_route/env_acc_route/lib/python3.10/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gs_lgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hp_lgbm = gs_lgbm.best_params_\n",
    "best_score_lgbm = gs_lgbm.best_score_\n",
    "best_estimator_lgbm = gs_lgbm.best_estimator_\n",
    "\n",
    "print(\"Meilleurs paramètres trouvés:\", best_hp_lgbm)\n",
    "print(\"Meilleur score de validation croisée:\", best_score_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgbm = best_estimator_lgbm.predict(X_test)\n",
    "\n",
    "cv_results_lgbm = gs_lgbm.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrice de confusion de lgbm classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_lgbm = confusion_matrix(y_test, y_pred_lgbm)\n",
    "print(\"Matrice de confusion :\\n\", cm_lgbm)\n",
    "\n",
    "row_sums_lgbm = cm_lgbm.sum(axis = 1)\n",
    "cm_percent_lgbm = (cm_lgbm.T / row_sums_lgbm).T * 100\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_percent_lgbm, annot = True, fmt = \".2f\", cmap = \"Blues\")\n",
    "plt.xlabel('Classe prédite')\n",
    "plt.ylabel('Classe réelle')\n",
    "plt.title('Matrice de confusion avec pourcentages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_acc_route",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
